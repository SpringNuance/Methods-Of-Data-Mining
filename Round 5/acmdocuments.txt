Formulation of Low-Order Dominant Poles for Y-Matrix of Interconnects: This paper presents an efficient approach to compute the dominant poles for the reduced-order admittance (Y parameter) matrix of lossy interconnects.
Our algorithm succeeds with high probability against an adaptive adversary, which can take over processors at any time during the protocol, up to the point of taking over arbitrarily close to a 1/3 fraction.
We present an all-pairs shortest path algorithm whose running time on a complete directed graph on n vertices whose edge weights are chosen independently and uniformly at random from [0,1] is O(n2), in expectation and with high probability.
We consider the problem of re-ranking the top-k documents returned by a retrieval system given some search query.
In this paper, we combine the learning-to-rank paradigm with the recent developments on axioms for information retrieval.
We outline important details on cross-validation techniques that can enhance the performance.
“Next-fit” allocation differs from first-fit in that a first-fit allocator commences its search for free space at a fixed end of memory, whereas a next-fit allocator commences its search wherever it previously stopped searching.
It is important to choose an appropriate network structure because simple networks are likely to under-fit while complex networks are less plastic and more computationally expensive to train.
Both of the LL-based algorithms in these papers attempt to minimize the reparsing on the original parse tree and the parse table.
In this paper, L2-norm Deep Belief Network (L2DBN) is proposed, which uses L2-norm regularization to optimize the network parameters of DBN.
The dramatic development of IT technology has increased absolute amount of data to store, analyze, and process for computers and it has also rapidly increased the amount of realtime processing for data stream
We present an algorithm achieving gathering in O(n2) rounds in expectation.
Let A and B two n×n matrices over a ring R (e.g., the reals or the integers) each containing at most m nonzero elements.
Firmware is the enable software of Internet of Things (IoT) devices, and its software vulnerabilities are one of the primary reason of IoT devices being exploited.
We present a new algorithm that multiplies A and B using O(m0.7n1.2+n2+o(1)) algebraic operations (i.e., multiplications, additions and subtractions) over R.
Efforts in “explainable AI” are under way, hopefully eliminating the “black-box” concept in future clinical decision tools.
Target distance (D) and target width (W), traditionally treated as independent variables in Fitts' target acquisition paradigm, are shown to suffer inextricable confounds with task difficulty.
This paper describes an NSF-funded initiative involving 600 underrepresented high school students and 60 teachers designed to introduce underrepresented students to the numerous and varied career opportunities in the computing sciences.
The gathering problem, where n autonomous robots with restricted capabilities are required to meet in a single point of the plane, is widely studied.
The information captured by IoT present an unprecedented opportunity to solve large-scale problems in those application domains to deliver services
Compliance with the information system (IS) security policy is an established theme in IS research for protecting the IS from user actions.
In this paper, we develop Re-Vibe, the first system that re-identifies people through footstep-induced floor vibrations.
I/O is emerging as a major bottleneck for machine learning training, especially in distributed environments.
In this paper, we attempt to improve the query likelihood function by bringing back the negative query generation.
In this paper, we propose a new on-chip interconnect scheme called Y-architecture, which can utilize the on-chip routing resources more efficiently than traditional Manhattan interconnect architecture by allowing wires routed in three directions (0°, 60°, and 120°).
We describe an algorithm for Byzantine agreement that is scalable in the sense that each processor sends only O(√n) bits, where n is the total number of processors.
This paper presents an image-based rendering (IBR) system based on RGB-D images.
In this paper we present a framework and methodology for aligning the business strategy and IT/IS for an organization offering an e-service in a multi-organizational setting.
The D Programming Language is a hybrid of C++ and modern scripting languages: it compiles statically to native code, but is also garbage collected.
However, the main aim is precisely to present an algorithm which gives the so-called minimal solutions: Boolean matrices M satisfying the equation with the least possible number of unity entries.
A number of algorithms have been proposed for LR incremental parsers, but few have been proposed for LL incremental parsers [1, 2].
I will discuss the use of graphical models for data mining.
Over the past decade, a pair of synchronization instructions known as LL/SC has emerged as the most suitable set of instructions to be used in the design of lock-free algorithms.
Our algorithm has latency that is polylogarithmic in n. 
Typical person re-identification (re-ID) systems rely on cameras to match the same person across different locations.
The Internet of Things (IoT) is the latest Internet evolution that incorporates a diverse range of things such as sensors, actuators, and services deployed by different organizations and individuals to support a variety of applications.
This subsection compares the state of the art methods and the proposed WRA-Net for the BoniRob dataset through the same method.
Hence, WRA-Net achieved higher values for PSNRand SSIM compared to the state-of-the-art methods.
It is shown that relative movement amplitude D/W(which determines difficulty) and absolute movement amplitude D (or scale) are the only two variables that can be manipulated independently in a Fitts' task experiment.
The area-under-the-curve (AUC) was the chosen performance metric for comparison and cross-validation was performed.
In this paper we present a tool to assist in teaching top-down and bottom-up analysis algorithms. The tool provides simulation for the following analysis algorithms: LL, SLR, LALR and LR.
In this paper, we formally show that standard gradient methods never overfit on separable data: If we run these methods for T iterations on a dataset of size m, both the empirical risk and the generalization error decrease at an essentially optimal rate of Õ(1/γ2T) up till T ∼ m.
This paper is concerned with goodness of fit evaluation for virtual commissioning modelling purposes.
The results showed that the optimal performance was achieved under natural complexification of the EANN and that back-propagation tended to over fit the data.
The second approach does not train models that generalize across tasks, but rather over-fit a single instance of a problem
This paper describes two significant contributions to the NILM community in an effort towards reproducible state-of-the-art research.
Accurate numerical results for a definite integral are easily obtained by simple substitutions of upper and lower bounds of integral into obtained approximate symbolic results
This paper presents an optimal algorithm for jumper insertion under the ratio upper-bound.
In particular, we argue that inter-tagger agreement is not a real upperbound for the Basque WSD task.
Lexicalized context-free grammar(LCFG) is an attractive compromise between the parsing efficiency of context-free grammar (CFG) and the elegance and lexical sensitivity of lexicalized tree adjoining grammar (LTAG).
