{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<div align=\"center\">\n",
        "\n",
        "# **CS-E4650 Methods of Data Mining**\n",
        "\n",
        "# **Exercise 5.4 Topics of text clusters**\n",
        "\n",
        "</div>"
      ],
      "metadata": {
        "id": "OgQTDzypVG6u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ":<div align=\"center\">\n",
        "    \n",
        "# **Group members**\n",
        "\n",
        "# **Nguyen Xuan Binh (887799)**\n",
        "\n",
        "# **Erald Shahinas (906845)**\n",
        "\n",
        "# **Alexander Pavlyuk (906829)**\n",
        "\n",
        "</div>\n",
        "\n",
        "</br>\n",
        "</br>\n",
        "</br>"
      ],
      "metadata": {
        "id": "ypgQ_i6PWTig"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlLOaXPbYNr6"
      },
      "source": [
        "# **Table of Contents**\n",
        "\n",
        "### 1. [Preprocessing](#1)\n",
        "### 2. [K-means clustering and topic detection](#2)\n",
        "### 3. [Additional experiments](#3)\n",
        "### 4. [Appendix](#5)\n",
        "\n",
        "</br>\n",
        "</br>\n",
        "</br>\n",
        "</br>\n",
        "</br>\n",
        "</br>\n",
        "</br>\n",
        "</br>\n",
        "</br>\n",
        "</br>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Learning goal: Clustering text data and techniques for describing topics of clusters*\n",
        "\n",
        "In this task, you should cluster a collection of short scientific texts and\n",
        "identify the main topics of each cluster. Ideally, you will indentify 3–10\n",
        "unique topics (areas or techniques of computer science) that describe majority of documents excluding possible outliers.\n",
        "In MC, you can find data set scopusabstracts.csv, which consists of abstracts of scientific papers from Scopus https://www.elsevier.com/products/\n",
        "scopus. Each line describes one document: its id, title, and abtract, separated by #."
      ],
      "metadata": {
        "id": "HpO1GiN0b6kC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1. Preprocessing**"
      ],
      "metadata": {
        "id": "S8n16N1lBkW4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(a) In the baseline solution, combine the title and abstract. Preprocess the\n",
        "data like in the previous task, but this time, create also **bigrams** (in\n",
        "addition to unigrams) as possible features. Since the number of features\n",
        "would otherwise be too high, it is suggested to use frequency-based\n",
        "filtering to prune out very frequent or extremely rare words/collocations\n",
        "(see parameters of sklearn TfidfVectorizer). Consider also adding new\n",
        "stopwords, if any frequent but uninformative words complicate later\n",
        "steps. When features are fine, present the data in the tf-idf form so\n",
        "that each document vector is normalized to unit L2 norm."
      ],
      "metadata": {
        "id": "V_bk2fZnCP8P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Describe briefly the preprocessing methods:\n",
        "tools (like nltk), in which order the steps were performed, stemmer,\n",
        "stopword list (including own additions), tf-idf version (equation), minimum or maximum frequencies (if any), and other possible steps or\n",
        "options that could affect the results."
      ],
      "metadata": {
        "id": "CMbYKhUWBi2Y"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noWC_99Yhxy7"
      },
      "source": [
        "All the calculations have been perfomed on JypyterHub (https://jupyter.cs.aalto.fi) in the Python notebook. Additionally, numpy (https://numpy.org/), matplotlib (https://matplotlib.org/), and pandas (https://pandas.pydata.org/) libraries have been imported to handle specific functions.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqK078JTEodD",
        "outputId": "316e8f66-f43c-4640-ed99-6475c6db6c84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CsVYEfz32m9r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "009ed57c-3823-4339-fc67-dc04855ba77c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.probability import FreqDist\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from string import punctuation\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.metrics import davies_bouldin_score\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "from copy import deepcopy\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "data_path = 'scopusabstracts.csv'\n",
        "\n",
        "# Read the data\n",
        "scopusdata = pd.read_csv('scopusabstracts.csv', sep='#')\n",
        "\n",
        "# Extract the text from each line. In the baseline solution, combine the title and abstract.\n",
        "corpus = [str1 + \" \" + str2 for str1, str2 in zip(scopusdata['TITLE'].to_list(), scopusdata['ABSTRACT'].to_list())]\n",
        "\n",
        "# some examples\n",
        "print('10 first titles + abstracts:')\n",
        "for i in corpus[:10]:\n",
        "    print(i)\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sxe0M3TQa84L",
        "outputId": "818245b7-9097-4702-d3ee-8b5791fe8209"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 first titles + abstracts:\n",
            "Anomaly detection in wide area imagery [Geniş alan görüntülerinde anomali tespiti] This study is about detecting anomalies in wide area imagery collected from an aircraft. The set of anomalies have been identified as anything out of the normal course of action. For this purpose, two different data sets were used and the experiments were carried out on these data sets. For anomaly detection, a convolutional neural network model that tries to generate the next image using past images is designed. The images were pre-processed before being given to the model. Anomaly detection is performed by comparing the estimated image and the true image. \n",
            "Person re-identification with deep kronecker-product matching and group-shuffling random walk Person re-identification (re-ID) aims to robustly measure visual affinities between person images. It has wide applications in intelligent surveillance by associating same persons' images across multiple cameras. It is generally treated as an image retrieval problem: Given a probe person image, the affinities between the probe image and gallery images (P2G affinities) are used to rank the retrieved gallery images. There exist two main challenges for effectively solving this problem. 1) Person images usually show significant variations because of different person poses and viewing angles. The spatial layouts and correspondences between person images are therefore vital information for tackling this problem. State-of-the-art methods either ignore such spatial variation or utilize extra pose information for handling the challenge. 2) Most existing person re-ID methods rank gallery images considering only P2G affinities but ignore the affinities between the gallery images (G2G affinity). Such affinities could provide important clues for accurate gallery image ranking but were only utilized in post-processing stages by current methods. In this article, we propose a unified end-to-end deep learning framework to tackle the two challenges. For handling viewpoint and pose variations between compared person images, we propose a novel Kronecker Product Matching operation to match and warp feature maps of different persons. Comparing warped feature maps results in more accurate P2G affinities. To fully utilize all available P2G and G2G affinities for accurately ranking gallery person images, a novel group-shuffling random walk operation is proposed. Both Kronecker Product Matching and Group-shuffling Random Walk operations are end-to-end trainable and are shown to improve the learned visual features if integrated in the deep learning framework. The proposed approach outperforms state-of-the-art methods on Market-1501, CUHK03 and DukeMTMC datasets, which demonstrates the effectiveness and generalization ability of our proposed approach. Code is available at https://github.com/YantaoShen/kpm_rw_person_reid. \n",
            "Crack detection in images of masonry using cnns While there is a significant body of research on crack detection by computer vision methods in concrete and asphalt, less attention has been given to masonry. We train a convolutional neural network (CNN) on images of brick walls built in a laboratory environment and test its ability to detect cracks in images of brick-and-mortar structures both in the laboratory and on real-world images taken from the internet. We also compare the performance of the CNN to a variety of simpler classifiers operating on handcrafted features. We find that the CNN performed better on the domain adaptation from laboratory to real-world images than these simple models. However, we also find that performance is significantly better in performing the reverse domain adaptation task, where the simple classifiers are trained on real-world images and tested on the laboratory images. This work demonstrates the ability to detect cracks in images of masonry using a variety of machine learning methods and provides guidance for improving the reliability of such models when performing domain adaptation for crack detection in masonry. \n",
            "Towards an energy efficient code generator for mobile phones Using a smartphone become the part of our everyday life in the last few years. These devices can help us in many areas of life (sport, job, weather etc.), but sometimes can be also very annoying because of the battery life time. That is why it is very important to find solutions, which can reduce the energy consumption of the smartphones. One possible method is the 'computation offloading' where a part of the processes are executed on a remote device (e.g. in the cloud). A lot of example has already shown, that computation offloading can reduce the energy usage of the mobile devices. However, the amount of energy saving may differ, as the decision making of the offloading process can be controlled with several techniques. Our decision making theory is based on the scheduling theory. In this paper, we are going to introduce a new system called ECGM (Energy efficient Code Generator for Mobile phones). ECGM decides automatically at compile time, which task should run on the smartphone and which task can be offloaded. The benefit of our system will be demonstrated through measurements based on our energy-efficiency scheduling technique. \n",
            "Sub-polyhedral scheduling using (Unit-)two-variable-per-inequality polyhedra Polyhedral compilation has been successful in the design and implementation of complex loop nest optimizers and parallelizing compilers. The algorithmic complexity and scalability limitations remain one important weakness. We address it using sub-polyhedral under-aproximations of the systems of constraints resulting from affine scheduling problems. We propose a sub-polyhedral scheduling technique using (Unit-)Two-Variable-Per-Inequality or (U)TVPI Polyhedra. This technique relies on simple polynomial time algorithms to under-approximate a general polyhedron into (U)TVPI polyhedra. We modify the state-of-the-art PLuTo compiler using our scheduling technique, and show that for a majority of the Polybench (2.0) kernels, the above under-approximations yield polyhedra that are non-empty. Solving the under-approximated system leads to asymptotic gains in complexity, and shows practically significant improvements when compared to a traditional LP solver. We also verify that code generated by our sub-polyhedral parallelization prototype matches the performance of PLuTo-optimized code when the under-approximation preserves feasibility. Copyright \n",
            "Extracting multiple viewpoint models from relational databases Much time in process mining projects is spent on finding and understanding data sources and extracting the event data needed. As a result, only a fraction of time is spent actually applying techniques to discover, control and predict the business process. Moreover, current process mining techniques assume a single case notion. However, in real-life processes often different case notions are intertwined. For example, events of the same order handling process may refer to customers, orders, order lines, deliveries, and payments. Therefore, we propose to use Multiple Viewpoint (MVP) models that relate events through objects and that relate activities through classes. The required event data are much closer to existing relational databases. MVP models provide a holistic view on the process, but also allow for the extraction of classical event logs using different viewpoints. This way existing process mining techniques can be used for each viewpoint without the need for new data extractions and transformations. We provide a toolchain allowing for the discovery of MVP models (annotated with performance and frequency information) from relational databases. Moreover, we demonstrate that classical process mining techniques can be applied to any selected viewpoint. \n",
            "A Program Result Checker for the Lexical Analysis of the GNU C Compiler In theory, program result checking has been established as a well-suited method to construct formally correct compiler frontends but it has never proved its practicality for real-life compilers. Such a proof is necessary to establish result checking as the method of choice to implement compilers correctly. We show that the lexical analysis of the GNU C compiler can be formally specified and checked within the theorem prover Isabelle/HOL utilizing program checking. Thereby we demonstrate that formal specification and verification techniques are able to handle real-life compilers. \n",
            "Advances in visual object tracking algorithm based on correlation filter [基于相关滤波的视觉目标跟踪算法新进展] With excellent comprehensive performance, correlation filter-based tracking algorithms have become a hotspot of the theoretical research and practical application in the field of visual object tracking. Despite many studies, there is still a lack of systematic analyses on the existing correlation filter-based tracking algorithms from the level of tracking framework. Therefore, starting from the basic framework of object tracking algorithms, the characteristics of correlation filter-based tracking algorithms are deeply analyzed, and their basic problems in each working stage are presented in this paper. On this basis, the main technological progress of correlation filter-based tracking algorithms and characteristics of corresponding algorithms in recent ten years are summarized, and 20 typical correlation filter-based tracking algorithms are evaluated and analyzed. Finally, the outstanding issues to be urgently solved and the future research directions of correlation filter-based tracking algorithms are discussed. \n",
            "A Study on Various Database Models: Relational, Graph, and Hybrid Databases Relational database is a popular database for storing various types of information. But due to the ever-increasing growth of data, it becomes hard to maintain and process the database. So, the graph model is becoming more and more popular since it can store and handle big data more efficiently compared to relational database. But both relational database and graph database have their own advantages and disadvantages. To overcome their limitations, they are combined to make a hybrid model. This paper discusses relational database, graph database, their advantages, their applications and also talks about hybrid model. \n",
            "Better Reporting of Studies on Artificial Intelligence: CONSORT-AI and Beyond An increasing number of studies on artificial intelligence (AI) are published in the dental and oral sciences. The reporting, but also further aspects of these studies, suffer from a range of limitations. Standards towards reporting, like the recently published Consolidated Standards of Reporting Trials (CONSORT)-AI extension can help to improve studies in this emerging field, and the Journal of Dental Research (JDR) encourages authors, reviewers, and readers to adhere to these standards. Notably, though, a wide range of aspects beyond reporting, located along various steps of the AI lifecycle, should be considered when conceiving, conducting, reporting, or evaluating studies on AI in dentistry. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing\n",
        "\n",
        "# Step 1: tokenization and lowercasing\n",
        "tokens_list = [word_tokenize(document) for document in corpus]\n",
        "\n",
        "lc_tokens_list = []\n",
        "\n",
        "for token_document in tokens_list:\n",
        "    lc_tokens_list.append([token.lower() for token in token_document])\n",
        "\n",
        "print('After tokenization and lowercasing:\\n')\n",
        "for i in lc_tokens_list[:10]:\n",
        "    print(i)\n",
        "print()\n",
        "\n",
        "# original number of tokens\n",
        "uniques = np.unique([token for token_document in lc_tokens_list for token in token_document])\n",
        "print(\"Original number of tokens: {}\\n\".format(len(uniques)))\n"
      ],
      "metadata": {
        "id": "P62bwpS6bC7o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d191a2ac-c18b-4a71-99fa-1bd49db9c6a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After tokenization and lowercasing:\n",
            "\n",
            "['anomaly', 'detection', 'in', 'wide', 'area', 'imagery', '[', 'geniş', 'alan', 'görüntülerinde', 'anomali', 'tespiti', ']', 'this', 'study', 'is', 'about', 'detecting', 'anomalies', 'in', 'wide', 'area', 'imagery', 'collected', 'from', 'an', 'aircraft', '.', 'the', 'set', 'of', 'anomalies', 'have', 'been', 'identified', 'as', 'anything', 'out', 'of', 'the', 'normal', 'course', 'of', 'action', '.', 'for', 'this', 'purpose', ',', 'two', 'different', 'data', 'sets', 'were', 'used', 'and', 'the', 'experiments', 'were', 'carried', 'out', 'on', 'these', 'data', 'sets', '.', 'for', 'anomaly', 'detection', ',', 'a', 'convolutional', 'neural', 'network', 'model', 'that', 'tries', 'to', 'generate', 'the', 'next', 'image', 'using', 'past', 'images', 'is', 'designed', '.', 'the', 'images', 'were', 'pre-processed', 'before', 'being', 'given', 'to', 'the', 'model', '.', 'anomaly', 'detection', 'is', 'performed', 'by', 'comparing', 'the', 'estimated', 'image', 'and', 'the', 'true', 'image', '.']\n",
            "['person', 're-identification', 'with', 'deep', 'kronecker-product', 'matching', 'and', 'group-shuffling', 'random', 'walk', 'person', 're-identification', '(', 're-id', ')', 'aims', 'to', 'robustly', 'measure', 'visual', 'affinities', 'between', 'person', 'images', '.', 'it', 'has', 'wide', 'applications', 'in', 'intelligent', 'surveillance', 'by', 'associating', 'same', 'persons', \"'\", 'images', 'across', 'multiple', 'cameras', '.', 'it', 'is', 'generally', 'treated', 'as', 'an', 'image', 'retrieval', 'problem', ':', 'given', 'a', 'probe', 'person', 'image', ',', 'the', 'affinities', 'between', 'the', 'probe', 'image', 'and', 'gallery', 'images', '(', 'p2g', 'affinities', ')', 'are', 'used', 'to', 'rank', 'the', 'retrieved', 'gallery', 'images', '.', 'there', 'exist', 'two', 'main', 'challenges', 'for', 'effectively', 'solving', 'this', 'problem', '.', '1', ')', 'person', 'images', 'usually', 'show', 'significant', 'variations', 'because', 'of', 'different', 'person', 'poses', 'and', 'viewing', 'angles', '.', 'the', 'spatial', 'layouts', 'and', 'correspondences', 'between', 'person', 'images', 'are', 'therefore', 'vital', 'information', 'for', 'tackling', 'this', 'problem', '.', 'state-of-the-art', 'methods', 'either', 'ignore', 'such', 'spatial', 'variation', 'or', 'utilize', 'extra', 'pose', 'information', 'for', 'handling', 'the', 'challenge', '.', '2', ')', 'most', 'existing', 'person', 're-id', 'methods', 'rank', 'gallery', 'images', 'considering', 'only', 'p2g', 'affinities', 'but', 'ignore', 'the', 'affinities', 'between', 'the', 'gallery', 'images', '(', 'g2g', 'affinity', ')', '.', 'such', 'affinities', 'could', 'provide', 'important', 'clues', 'for', 'accurate', 'gallery', 'image', 'ranking', 'but', 'were', 'only', 'utilized', 'in', 'post-processing', 'stages', 'by', 'current', 'methods', '.', 'in', 'this', 'article', ',', 'we', 'propose', 'a', 'unified', 'end-to-end', 'deep', 'learning', 'framework', 'to', 'tackle', 'the', 'two', 'challenges', '.', 'for', 'handling', 'viewpoint', 'and', 'pose', 'variations', 'between', 'compared', 'person', 'images', ',', 'we', 'propose', 'a', 'novel', 'kronecker', 'product', 'matching', 'operation', 'to', 'match', 'and', 'warp', 'feature', 'maps', 'of', 'different', 'persons', '.', 'comparing', 'warped', 'feature', 'maps', 'results', 'in', 'more', 'accurate', 'p2g', 'affinities', '.', 'to', 'fully', 'utilize', 'all', 'available', 'p2g', 'and', 'g2g', 'affinities', 'for', 'accurately', 'ranking', 'gallery', 'person', 'images', ',', 'a', 'novel', 'group-shuffling', 'random', 'walk', 'operation', 'is', 'proposed', '.', 'both', 'kronecker', 'product', 'matching', 'and', 'group-shuffling', 'random', 'walk', 'operations', 'are', 'end-to-end', 'trainable', 'and', 'are', 'shown', 'to', 'improve', 'the', 'learned', 'visual', 'features', 'if', 'integrated', 'in', 'the', 'deep', 'learning', 'framework', '.', 'the', 'proposed', 'approach', 'outperforms', 'state-of-the-art', 'methods', 'on', 'market-1501', ',', 'cuhk03', 'and', 'dukemtmc', 'datasets', ',', 'which', 'demonstrates', 'the', 'effectiveness', 'and', 'generalization', 'ability', 'of', 'our', 'proposed', 'approach', '.', 'code', 'is', 'available', 'at', 'https', ':', '//github.com/yantaoshen/kpm_rw_person_reid', '.']\n",
            "['crack', 'detection', 'in', 'images', 'of', 'masonry', 'using', 'cnns', 'while', 'there', 'is', 'a', 'significant', 'body', 'of', 'research', 'on', 'crack', 'detection', 'by', 'computer', 'vision', 'methods', 'in', 'concrete', 'and', 'asphalt', ',', 'less', 'attention', 'has', 'been', 'given', 'to', 'masonry', '.', 'we', 'train', 'a', 'convolutional', 'neural', 'network', '(', 'cnn', ')', 'on', 'images', 'of', 'brick', 'walls', 'built', 'in', 'a', 'laboratory', 'environment', 'and', 'test', 'its', 'ability', 'to', 'detect', 'cracks', 'in', 'images', 'of', 'brick-and-mortar', 'structures', 'both', 'in', 'the', 'laboratory', 'and', 'on', 'real-world', 'images', 'taken', 'from', 'the', 'internet', '.', 'we', 'also', 'compare', 'the', 'performance', 'of', 'the', 'cnn', 'to', 'a', 'variety', 'of', 'simpler', 'classifiers', 'operating', 'on', 'handcrafted', 'features', '.', 'we', 'find', 'that', 'the', 'cnn', 'performed', 'better', 'on', 'the', 'domain', 'adaptation', 'from', 'laboratory', 'to', 'real-world', 'images', 'than', 'these', 'simple', 'models', '.', 'however', ',', 'we', 'also', 'find', 'that', 'performance', 'is', 'significantly', 'better', 'in', 'performing', 'the', 'reverse', 'domain', 'adaptation', 'task', ',', 'where', 'the', 'simple', 'classifiers', 'are', 'trained', 'on', 'real-world', 'images', 'and', 'tested', 'on', 'the', 'laboratory', 'images', '.', 'this', 'work', 'demonstrates', 'the', 'ability', 'to', 'detect', 'cracks', 'in', 'images', 'of', 'masonry', 'using', 'a', 'variety', 'of', 'machine', 'learning', 'methods', 'and', 'provides', 'guidance', 'for', 'improving', 'the', 'reliability', 'of', 'such', 'models', 'when', 'performing', 'domain', 'adaptation', 'for', 'crack', 'detection', 'in', 'masonry', '.']\n",
            "['towards', 'an', 'energy', 'efficient', 'code', 'generator', 'for', 'mobile', 'phones', 'using', 'a', 'smartphone', 'become', 'the', 'part', 'of', 'our', 'everyday', 'life', 'in', 'the', 'last', 'few', 'years', '.', 'these', 'devices', 'can', 'help', 'us', 'in', 'many', 'areas', 'of', 'life', '(', 'sport', ',', 'job', ',', 'weather', 'etc', '.', ')', ',', 'but', 'sometimes', 'can', 'be', 'also', 'very', 'annoying', 'because', 'of', 'the', 'battery', 'life', 'time', '.', 'that', 'is', 'why', 'it', 'is', 'very', 'important', 'to', 'find', 'solutions', ',', 'which', 'can', 'reduce', 'the', 'energy', 'consumption', 'of', 'the', 'smartphones', '.', 'one', 'possible', 'method', 'is', 'the', \"'computation\", 'offloading', \"'\", 'where', 'a', 'part', 'of', 'the', 'processes', 'are', 'executed', 'on', 'a', 'remote', 'device', '(', 'e.g', '.', 'in', 'the', 'cloud', ')', '.', 'a', 'lot', 'of', 'example', 'has', 'already', 'shown', ',', 'that', 'computation', 'offloading', 'can', 'reduce', 'the', 'energy', 'usage', 'of', 'the', 'mobile', 'devices', '.', 'however', ',', 'the', 'amount', 'of', 'energy', 'saving', 'may', 'differ', ',', 'as', 'the', 'decision', 'making', 'of', 'the', 'offloading', 'process', 'can', 'be', 'controlled', 'with', 'several', 'techniques', '.', 'our', 'decision', 'making', 'theory', 'is', 'based', 'on', 'the', 'scheduling', 'theory', '.', 'in', 'this', 'paper', ',', 'we', 'are', 'going', 'to', 'introduce', 'a', 'new', 'system', 'called', 'ecgm', '(', 'energy', 'efficient', 'code', 'generator', 'for', 'mobile', 'phones', ')', '.', 'ecgm', 'decides', 'automatically', 'at', 'compile', 'time', ',', 'which', 'task', 'should', 'run', 'on', 'the', 'smartphone', 'and', 'which', 'task', 'can', 'be', 'offloaded', '.', 'the', 'benefit', 'of', 'our', 'system', 'will', 'be', 'demonstrated', 'through', 'measurements', 'based', 'on', 'our', 'energy-efficiency', 'scheduling', 'technique', '.']\n",
            "['sub-polyhedral', 'scheduling', 'using', '(', 'unit-', ')', 'two-variable-per-inequality', 'polyhedra', 'polyhedral', 'compilation', 'has', 'been', 'successful', 'in', 'the', 'design', 'and', 'implementation', 'of', 'complex', 'loop', 'nest', 'optimizers', 'and', 'parallelizing', 'compilers', '.', 'the', 'algorithmic', 'complexity', 'and', 'scalability', 'limitations', 'remain', 'one', 'important', 'weakness', '.', 'we', 'address', 'it', 'using', 'sub-polyhedral', 'under-aproximations', 'of', 'the', 'systems', 'of', 'constraints', 'resulting', 'from', 'affine', 'scheduling', 'problems', '.', 'we', 'propose', 'a', 'sub-polyhedral', 'scheduling', 'technique', 'using', '(', 'unit-', ')', 'two-variable-per-inequality', 'or', '(', 'u', ')', 'tvpi', 'polyhedra', '.', 'this', 'technique', 'relies', 'on', 'simple', 'polynomial', 'time', 'algorithms', 'to', 'under-approximate', 'a', 'general', 'polyhedron', 'into', '(', 'u', ')', 'tvpi', 'polyhedra', '.', 'we', 'modify', 'the', 'state-of-the-art', 'pluto', 'compiler', 'using', 'our', 'scheduling', 'technique', ',', 'and', 'show', 'that', 'for', 'a', 'majority', 'of', 'the', 'polybench', '(', '2.0', ')', 'kernels', ',', 'the', 'above', 'under-approximations', 'yield', 'polyhedra', 'that', 'are', 'non-empty', '.', 'solving', 'the', 'under-approximated', 'system', 'leads', 'to', 'asymptotic', 'gains', 'in', 'complexity', ',', 'and', 'shows', 'practically', 'significant', 'improvements', 'when', 'compared', 'to', 'a', 'traditional', 'lp', 'solver', '.', 'we', 'also', 'verify', 'that', 'code', 'generated', 'by', 'our', 'sub-polyhedral', 'parallelization', 'prototype', 'matches', 'the', 'performance', 'of', 'pluto-optimized', 'code', 'when', 'the', 'under-approximation', 'preserves', 'feasibility', '.', 'copyright']\n",
            "['extracting', 'multiple', 'viewpoint', 'models', 'from', 'relational', 'databases', 'much', 'time', 'in', 'process', 'mining', 'projects', 'is', 'spent', 'on', 'finding', 'and', 'understanding', 'data', 'sources', 'and', 'extracting', 'the', 'event', 'data', 'needed', '.', 'as', 'a', 'result', ',', 'only', 'a', 'fraction', 'of', 'time', 'is', 'spent', 'actually', 'applying', 'techniques', 'to', 'discover', ',', 'control', 'and', 'predict', 'the', 'business', 'process', '.', 'moreover', ',', 'current', 'process', 'mining', 'techniques', 'assume', 'a', 'single', 'case', 'notion', '.', 'however', ',', 'in', 'real-life', 'processes', 'often', 'different', 'case', 'notions', 'are', 'intertwined', '.', 'for', 'example', ',', 'events', 'of', 'the', 'same', 'order', 'handling', 'process', 'may', 'refer', 'to', 'customers', ',', 'orders', ',', 'order', 'lines', ',', 'deliveries', ',', 'and', 'payments', '.', 'therefore', ',', 'we', 'propose', 'to', 'use', 'multiple', 'viewpoint', '(', 'mvp', ')', 'models', 'that', 'relate', 'events', 'through', 'objects', 'and', 'that', 'relate', 'activities', 'through', 'classes', '.', 'the', 'required', 'event', 'data', 'are', 'much', 'closer', 'to', 'existing', 'relational', 'databases', '.', 'mvp', 'models', 'provide', 'a', 'holistic', 'view', 'on', 'the', 'process', ',', 'but', 'also', 'allow', 'for', 'the', 'extraction', 'of', 'classical', 'event', 'logs', 'using', 'different', 'viewpoints', '.', 'this', 'way', 'existing', 'process', 'mining', 'techniques', 'can', 'be', 'used', 'for', 'each', 'viewpoint', 'without', 'the', 'need', 'for', 'new', 'data', 'extractions', 'and', 'transformations', '.', 'we', 'provide', 'a', 'toolchain', 'allowing', 'for', 'the', 'discovery', 'of', 'mvp', 'models', '(', 'annotated', 'with', 'performance', 'and', 'frequency', 'information', ')', 'from', 'relational', 'databases', '.', 'moreover', ',', 'we', 'demonstrate', 'that', 'classical', 'process', 'mining', 'techniques', 'can', 'be', 'applied', 'to', 'any', 'selected', 'viewpoint', '.']\n",
            "['a', 'program', 'result', 'checker', 'for', 'the', 'lexical', 'analysis', 'of', 'the', 'gnu', 'c', 'compiler', 'in', 'theory', ',', 'program', 'result', 'checking', 'has', 'been', 'established', 'as', 'a', 'well-suited', 'method', 'to', 'construct', 'formally', 'correct', 'compiler', 'frontends', 'but', 'it', 'has', 'never', 'proved', 'its', 'practicality', 'for', 'real-life', 'compilers', '.', 'such', 'a', 'proof', 'is', 'necessary', 'to', 'establish', 'result', 'checking', 'as', 'the', 'method', 'of', 'choice', 'to', 'implement', 'compilers', 'correctly', '.', 'we', 'show', 'that', 'the', 'lexical', 'analysis', 'of', 'the', 'gnu', 'c', 'compiler', 'can', 'be', 'formally', 'specified', 'and', 'checked', 'within', 'the', 'theorem', 'prover', 'isabelle/hol', 'utilizing', 'program', 'checking', '.', 'thereby', 'we', 'demonstrate', 'that', 'formal', 'specification', 'and', 'verification', 'techniques', 'are', 'able', 'to', 'handle', 'real-life', 'compilers', '.']\n",
            "['advances', 'in', 'visual', 'object', 'tracking', 'algorithm', 'based', 'on', 'correlation', 'filter', '[', '基于相关滤波的视觉目标跟踪算法新进展', ']', 'with', 'excellent', 'comprehensive', 'performance', ',', 'correlation', 'filter-based', 'tracking', 'algorithms', 'have', 'become', 'a', 'hotspot', 'of', 'the', 'theoretical', 'research', 'and', 'practical', 'application', 'in', 'the', 'field', 'of', 'visual', 'object', 'tracking', '.', 'despite', 'many', 'studies', ',', 'there', 'is', 'still', 'a', 'lack', 'of', 'systematic', 'analyses', 'on', 'the', 'existing', 'correlation', 'filter-based', 'tracking', 'algorithms', 'from', 'the', 'level', 'of', 'tracking', 'framework', '.', 'therefore', ',', 'starting', 'from', 'the', 'basic', 'framework', 'of', 'object', 'tracking', 'algorithms', ',', 'the', 'characteristics', 'of', 'correlation', 'filter-based', 'tracking', 'algorithms', 'are', 'deeply', 'analyzed', ',', 'and', 'their', 'basic', 'problems', 'in', 'each', 'working', 'stage', 'are', 'presented', 'in', 'this', 'paper', '.', 'on', 'this', 'basis', ',', 'the', 'main', 'technological', 'progress', 'of', 'correlation', 'filter-based', 'tracking', 'algorithms', 'and', 'characteristics', 'of', 'corresponding', 'algorithms', 'in', 'recent', 'ten', 'years', 'are', 'summarized', ',', 'and', '20', 'typical', 'correlation', 'filter-based', 'tracking', 'algorithms', 'are', 'evaluated', 'and', 'analyzed', '.', 'finally', ',', 'the', 'outstanding', 'issues', 'to', 'be', 'urgently', 'solved', 'and', 'the', 'future', 'research', 'directions', 'of', 'correlation', 'filter-based', 'tracking', 'algorithms', 'are', 'discussed', '.']\n",
            "['a', 'study', 'on', 'various', 'database', 'models', ':', 'relational', ',', 'graph', ',', 'and', 'hybrid', 'databases', 'relational', 'database', 'is', 'a', 'popular', 'database', 'for', 'storing', 'various', 'types', 'of', 'information', '.', 'but', 'due', 'to', 'the', 'ever-increasing', 'growth', 'of', 'data', ',', 'it', 'becomes', 'hard', 'to', 'maintain', 'and', 'process', 'the', 'database', '.', 'so', ',', 'the', 'graph', 'model', 'is', 'becoming', 'more', 'and', 'more', 'popular', 'since', 'it', 'can', 'store', 'and', 'handle', 'big', 'data', 'more', 'efficiently', 'compared', 'to', 'relational', 'database', '.', 'but', 'both', 'relational', 'database', 'and', 'graph', 'database', 'have', 'their', 'own', 'advantages', 'and', 'disadvantages', '.', 'to', 'overcome', 'their', 'limitations', ',', 'they', 'are', 'combined', 'to', 'make', 'a', 'hybrid', 'model', '.', 'this', 'paper', 'discusses', 'relational', 'database', ',', 'graph', 'database', ',', 'their', 'advantages', ',', 'their', 'applications', 'and', 'also', 'talks', 'about', 'hybrid', 'model', '.']\n",
            "['better', 'reporting', 'of', 'studies', 'on', 'artificial', 'intelligence', ':', 'consort-ai', 'and', 'beyond', 'an', 'increasing', 'number', 'of', 'studies', 'on', 'artificial', 'intelligence', '(', 'ai', ')', 'are', 'published', 'in', 'the', 'dental', 'and', 'oral', 'sciences', '.', 'the', 'reporting', ',', 'but', 'also', 'further', 'aspects', 'of', 'these', 'studies', ',', 'suffer', 'from', 'a', 'range', 'of', 'limitations', '.', 'standards', 'towards', 'reporting', ',', 'like', 'the', 'recently', 'published', 'consolidated', 'standards', 'of', 'reporting', 'trials', '(', 'consort', ')', '-ai', 'extension', 'can', 'help', 'to', 'improve', 'studies', 'in', 'this', 'emerging', 'field', ',', 'and', 'the', 'journal', 'of', 'dental', 'research', '(', 'jdr', ')', 'encourages', 'authors', ',', 'reviewers', ',', 'and', 'readers', 'to', 'adhere', 'to', 'these', 'standards', '.', 'notably', ',', 'though', ',', 'a', 'wide', 'range', 'of', 'aspects', 'beyond', 'reporting', ',', 'located', 'along', 'various', 'steps', 'of', 'the', 'ai', 'lifecycle', ',', 'should', 'be', 'considered', 'when', 'conceiving', ',', 'conducting', ',', 'reporting', ',', 'or', 'evaluating', 'studies', 'on', 'ai', 'in', 'dentistry', '.']\n",
            "\n",
            "Original number of tokens: 15882\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Steps 2 and 3: remove stop words and punctuation\n",
        "stop_words = set(stopwords.words('english'))\n",
        "print('NLTK stopwords:')\n",
        "print(stop_words)\n",
        "print()\n",
        "\n",
        "#stop_words.update([\"use\", \"data\", \"system\", \"propos\"])\n",
        "\n",
        "# Here we include the punctuation in the stop words set. There are alternative ways to remove punctuation.\n",
        "\n",
        "\n",
        "stop_words.update(punctuation)\n",
        "\n",
        "# For the field of computer science research papers, in addition to the standard English stop words,\n",
        "# we might consider adding words that serves little meanings\n",
        "\n",
        "# stop_words.update({\"use\", \"data\", \"system\", \"proposed\", \"study\", \"results\", \"analysis\", \"model\",\n",
        "#                 \"approach\", \"methods\", \"research\", \"application\", \"technique\", \"performance\",\n",
        "#                 \"algorithm\", \"process\", \"problem\", \"solution\"})\n",
        "\n",
        "#you can check updated stopwords\n",
        "#print(stop_words)\n",
        "\n",
        "filtered_sentence = []\n",
        "for i in lc_tokens_list:\n",
        "    filtered_sentence.append([token for token in i if token not in stop_words])\n",
        "\n",
        "# Numbers are also removed\n",
        "filtered_sentence = [ ' '.join(i) for i in filtered_sentence ]\n",
        "filtered_sentence = [ re.sub(r'\\d+', '', sentence) for sentence in filtered_sentence ]\n",
        "\n",
        "# number of tokens\n",
        "uniques = np.unique([tok for doc in filtered_sentence for tok in doc.split()])\n",
        "print(\"Number of tokens after stopword and punctuation removal: {}\\n\".format(len(uniques)))\n",
        "\n",
        "\n",
        "print('After removing stop words, punctuation and numbers:')\n",
        "for sentence in filtered_sentence[:10]:\n",
        "    print(sentence)\n",
        "print()"
      ],
      "metadata": {
        "id": "J92DadQwbFQ7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1fbe2b2-7133-4916-8199-2ab8dcf6e149"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLTK stopwords:\n",
            "{'mightn', 'each', \"wouldn't\", 'just', \"wasn't\", 'of', 'both', \"hadn't\", 's', 'now', 'isn', 'don', 'itself', 'through', 'herself', 'how', \"it's\", 'doesn', 'm', 'haven', 'we', 'as', 'up', 'theirs', \"shouldn't\", \"isn't\", 'an', 'so', 'which', 'by', 'be', 'further', 'having', 'was', \"mustn't\", 'again', 'before', \"you'd\", 'out', 'yourselves', 'have', 'such', 'hasn', \"weren't\", 'she', 'there', 'from', 'once', 'yourself', 'until', 'between', 'to', \"you're\", 'after', 'it', 'down', 'only', 'then', 'against', 'yours', 'those', 'themselves', 're', 'own', 've', 'a', 'in', 'do', 'are', 'whom', 'with', 'were', 'they', 'when', 'where', \"won't\", \"hasn't\", 'any', 'off', 'no', 'hadn', 'about', 'll', 'am', 'all', 'than', \"you've\", 'most', 'he', 'being', 'does', 'ours', 'y', \"couldn't\", \"don't\", 'been', 'the', \"doesn't\", 'shan', \"didn't\", 'wasn', \"that'll\", 'them', 'if', 'that', 'or', 'under', 'their', 'while', 'o', 'will', 'should', \"mightn't\", 'mustn', 'your', 'couldn', 'shouldn', 'very', 'why', 'ma', 'doing', 'same', \"you'll\", 'did', 'what', 'too', 'needn', 'few', 'him', 'can', \"needn't\", 'but', 'at', 'nor', 'wouldn', 'more', 'is', 'won', 'myself', 'me', 'its', 'd', 'weren', 'ourselves', 'into', \"aren't\", 'hers', 'during', 'you', 'on', \"shan't\", 'this', 'aren', \"haven't\", 'has', 'some', 'these', 'other', 'himself', 'and', 'over', 'i', 'ain', 'because', 'for', 't', 'here', 'didn', 'above', 'below', \"should've\", \"she's\", 'my', 'who', 'his', 'our', 'her', 'not', 'had'}\n",
            "\n",
            "Number of tokens after stopword and punctuation removal: 14820\n",
            "\n",
            "After removing stop words, punctuation and numbers:\n",
            "anomaly detection wide area imagery geniş alan görüntülerinde anomali tespiti study detecting anomalies wide area imagery collected aircraft set anomalies identified anything normal course action purpose two different data sets used experiments carried data sets anomaly detection convolutional neural network model tries generate next image using past images designed images pre-processed given model anomaly detection performed comparing estimated image true image\n",
            "person re-identification deep kronecker-product matching group-shuffling random walk person re-identification re-id aims robustly measure visual affinities person images wide applications intelligent surveillance associating persons images across multiple cameras generally treated image retrieval problem given probe person image affinities probe image gallery images pg affinities used rank retrieved gallery images exist two main challenges effectively solving problem  person images usually show significant variations different person poses viewing angles spatial layouts correspondences person images therefore vital information tackling problem state-of-the-art methods either ignore spatial variation utilize extra pose information handling challenge  existing person re-id methods rank gallery images considering pg affinities ignore affinities gallery images gg affinity affinities could provide important clues accurate gallery image ranking utilized post-processing stages current methods article propose unified end-to-end deep learning framework tackle two challenges handling viewpoint pose variations compared person images propose novel kronecker product matching operation match warp feature maps different persons comparing warped feature maps results accurate pg affinities fully utilize available pg gg affinities accurately ranking gallery person images novel group-shuffling random walk operation proposed kronecker product matching group-shuffling random walk operations end-to-end trainable shown improve learned visual features integrated deep learning framework proposed approach outperforms state-of-the-art methods market- cuhk dukemtmc datasets demonstrates effectiveness generalization ability proposed approach code available https //github.com/yantaoshen/kpm_rw_person_reid\n",
            "crack detection images masonry using cnns significant body research crack detection computer vision methods concrete asphalt less attention given masonry train convolutional neural network cnn images brick walls built laboratory environment test ability detect cracks images brick-and-mortar structures laboratory real-world images taken internet also compare performance cnn variety simpler classifiers operating handcrafted features find cnn performed better domain adaptation laboratory real-world images simple models however also find performance significantly better performing reverse domain adaptation task simple classifiers trained real-world images tested laboratory images work demonstrates ability detect cracks images masonry using variety machine learning methods provides guidance improving reliability models performing domain adaptation crack detection masonry\n",
            "towards energy efficient code generator mobile phones using smartphone become part everyday life last years devices help us many areas life sport job weather etc sometimes also annoying battery life time important find solutions reduce energy consumption smartphones one possible method 'computation offloading part processes executed remote device e.g cloud lot example already shown computation offloading reduce energy usage mobile devices however amount energy saving may differ decision making offloading process controlled several techniques decision making theory based scheduling theory paper going introduce new system called ecgm energy efficient code generator mobile phones ecgm decides automatically compile time task run smartphone task offloaded benefit system demonstrated measurements based energy-efficiency scheduling technique\n",
            "sub-polyhedral scheduling using unit- two-variable-per-inequality polyhedra polyhedral compilation successful design implementation complex loop nest optimizers parallelizing compilers algorithmic complexity scalability limitations remain one important weakness address using sub-polyhedral under-aproximations systems constraints resulting affine scheduling problems propose sub-polyhedral scheduling technique using unit- two-variable-per-inequality u tvpi polyhedra technique relies simple polynomial time algorithms under-approximate general polyhedron u tvpi polyhedra modify state-of-the-art pluto compiler using scheduling technique show majority polybench . kernels under-approximations yield polyhedra non-empty solving under-approximated system leads asymptotic gains complexity shows practically significant improvements compared traditional lp solver also verify code generated sub-polyhedral parallelization prototype matches performance pluto-optimized code under-approximation preserves feasibility copyright\n",
            "extracting multiple viewpoint models relational databases much time process mining projects spent finding understanding data sources extracting event data needed result fraction time spent actually applying techniques discover control predict business process moreover current process mining techniques assume single case notion however real-life processes often different case notions intertwined example events order handling process may refer customers orders order lines deliveries payments therefore propose use multiple viewpoint mvp models relate events objects relate activities classes required event data much closer existing relational databases mvp models provide holistic view process also allow extraction classical event logs using different viewpoints way existing process mining techniques used viewpoint without need new data extractions transformations provide toolchain allowing discovery mvp models annotated performance frequency information relational databases moreover demonstrate classical process mining techniques applied selected viewpoint\n",
            "program result checker lexical analysis gnu c compiler theory program result checking established well-suited method construct formally correct compiler frontends never proved practicality real-life compilers proof necessary establish result checking method choice implement compilers correctly show lexical analysis gnu c compiler formally specified checked within theorem prover isabelle/hol utilizing program checking thereby demonstrate formal specification verification techniques able handle real-life compilers\n",
            "advances visual object tracking algorithm based correlation filter 基于相关滤波的视觉目标跟踪算法新进展 excellent comprehensive performance correlation filter-based tracking algorithms become hotspot theoretical research practical application field visual object tracking despite many studies still lack systematic analyses existing correlation filter-based tracking algorithms level tracking framework therefore starting basic framework object tracking algorithms characteristics correlation filter-based tracking algorithms deeply analyzed basic problems working stage presented paper basis main technological progress correlation filter-based tracking algorithms characteristics corresponding algorithms recent ten years summarized  typical correlation filter-based tracking algorithms evaluated analyzed finally outstanding issues urgently solved future research directions correlation filter-based tracking algorithms discussed\n",
            "study various database models relational graph hybrid databases relational database popular database storing various types information due ever-increasing growth data becomes hard maintain process database graph model becoming popular since store handle big data efficiently compared relational database relational database graph database advantages disadvantages overcome limitations combined make hybrid model paper discusses relational database graph database advantages applications also talks hybrid model\n",
            "better reporting studies artificial intelligence consort-ai beyond increasing number studies artificial intelligence ai published dental oral sciences reporting also aspects studies suffer range limitations standards towards reporting like recently published consolidated standards reporting trials consort -ai extension help improve studies emerging field journal dental research jdr encourages authors reviewers readers adhere standards notably though wide range aspects beyond reporting located along various steps ai lifecycle considered conceiving conducting reporting evaluating studies ai dentistry\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: stemming\n",
        "porter = PorterStemmer()\n",
        "\n",
        "#or snowball stemmer\n",
        "#stemmer = SnowballStemmer(\"english\",ignore_stopwords=True)\n",
        "stemmed_tokens_list = []\n",
        "\n",
        "for i in filtered_sentence:\n",
        "\tstemmed_tokens_list.append([porter.stem(j) for j in i.split()])\n",
        "\n",
        "# number of tokens\n",
        "uniques = np.unique([tok for doc in stemmed_tokens_list for tok in doc])\n",
        "print(\"Number of tokens after stemming: {}\\n\".format(len(uniques)))\n",
        "\n",
        "print('After stemming:')\n",
        "for tokens in stemmed_tokens_list[:10]:\n",
        "\tfor token in tokens:\n",
        "\t\tprint(token,end=\" \")\n",
        "\tprint(\" \")\n"
      ],
      "metadata": {
        "id": "RIQdkfyTbHm3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "777e21a2-ea04-4bd5-fdf9-4b8f889e2b2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of tokens after stemming: 10259\n",
            "\n",
            "After stemming:\n",
            "anomali detect wide area imageri geniş alan görüntülerind anomali tespiti studi detect anomali wide area imageri collect aircraft set anomali identifi anyth normal cours action purpos two differ data set use experi carri data set anomali detect convolut neural network model tri gener next imag use past imag design imag pre-process given model anomali detect perform compar estim imag true imag  \n",
            "person re-identif deep kronecker-product match group-shuffl random walk person re-identif re-id aim robustli measur visual affin person imag wide applic intellig surveil associ person imag across multipl camera gener treat imag retriev problem given probe person imag affin probe imag galleri imag pg affin use rank retriev galleri imag exist two main challeng effect solv problem person imag usual show signific variat differ person pose view angl spatial layout correspond person imag therefor vital inform tackl problem state-of-the-art method either ignor spatial variat util extra pose inform handl challeng exist person re-id method rank galleri imag consid pg affin ignor affin galleri imag gg affin affin could provid import clue accur galleri imag rank util post-process stage current method articl propos unifi end-to-end deep learn framework tackl two challeng handl viewpoint pose variat compar person imag propos novel kroneck product match oper match warp featur map differ person compar warp featur map result accur pg affin fulli util avail pg gg affin accur rank galleri person imag novel group-shuffl random walk oper propos kroneck product match group-shuffl random walk oper end-to-end trainabl shown improv learn visual featur integr deep learn framework propos approach outperform state-of-the-art method market- cuhk dukemtmc dataset demonstr effect gener abil propos approach code avail http //github.com/yantaoshen/kpm_rw_person_reid  \n",
            "crack detect imag masonri use cnn signific bodi research crack detect comput vision method concret asphalt less attent given masonri train convolut neural network cnn imag brick wall built laboratori environ test abil detect crack imag brick-and-mortar structur laboratori real-world imag taken internet also compar perform cnn varieti simpler classifi oper handcraft featur find cnn perform better domain adapt laboratori real-world imag simpl model howev also find perform significantli better perform revers domain adapt task simpl classifi train real-world imag test laboratori imag work demonstr abil detect crack imag masonri use varieti machin learn method provid guidanc improv reliabl model perform domain adapt crack detect masonri  \n",
            "toward energi effici code gener mobil phone use smartphon becom part everyday life last year devic help us mani area life sport job weather etc sometim also annoy batteri life time import find solut reduc energi consumpt smartphon one possibl method 'comput offload part process execut remot devic e.g cloud lot exampl alreadi shown comput offload reduc energi usag mobil devic howev amount energi save may differ decis make offload process control sever techniqu decis make theori base schedul theori paper go introduc new system call ecgm energi effici code gener mobil phone ecgm decid automat compil time task run smartphon task offload benefit system demonstr measur base energy-effici schedul techniqu  \n",
            "sub-polyhedr schedul use unit- two-variable-per-inequ polyhedra polyhedr compil success design implement complex loop nest optim parallel compil algorithm complex scalabl limit remain one import weak address use sub-polyhedr under-aproxim system constraint result affin schedul problem propos sub-polyhedr schedul techniqu use unit- two-variable-per-inequ u tvpi polyhedra techniqu reli simpl polynomi time algorithm under-approxim gener polyhedron u tvpi polyhedra modifi state-of-the-art pluto compil use schedul techniqu show major polybench . kernel under-approxim yield polyhedra non-empti solv under-approxim system lead asymptot gain complex show practic signific improv compar tradit lp solver also verifi code gener sub-polyhedr parallel prototyp match perform pluto-optim code under-approxim preserv feasibl copyright  \n",
            "extract multipl viewpoint model relat databas much time process mine project spent find understand data sourc extract event data need result fraction time spent actual appli techniqu discov control predict busi process moreov current process mine techniqu assum singl case notion howev real-lif process often differ case notion intertwin exampl event order handl process may refer custom order order line deliveri payment therefor propos use multipl viewpoint mvp model relat event object relat activ class requir event data much closer exist relat databas mvp model provid holist view process also allow extract classic event log use differ viewpoint way exist process mine techniqu use viewpoint without need new data extract transform provid toolchain allow discoveri mvp model annot perform frequenc inform relat databas moreov demonstr classic process mine techniqu appli select viewpoint  \n",
            "program result checker lexic analysi gnu c compil theori program result check establish well-suit method construct formal correct compil frontend never prove practic real-lif compil proof necessari establish result check method choic implement compil correctli show lexic analysi gnu c compil formal specifi check within theorem prover isabelle/hol util program check therebi demonstr formal specif verif techniqu abl handl real-lif compil  \n",
            "advanc visual object track algorithm base correl filter 基于相关滤波的视觉目标跟踪算法新进展 excel comprehens perform correl filter-bas track algorithm becom hotspot theoret research practic applic field visual object track despit mani studi still lack systemat analys exist correl filter-bas track algorithm level track framework therefor start basic framework object track algorithm characterist correl filter-bas track algorithm deepli analyz basic problem work stage present paper basi main technolog progress correl filter-bas track algorithm characterist correspond algorithm recent ten year summar typic correl filter-bas track algorithm evalu analyz final outstand issu urgent solv futur research direct correl filter-bas track algorithm discuss  \n",
            "studi variou databas model relat graph hybrid databas relat databas popular databas store variou type inform due ever-increas growth data becom hard maintain process databas graph model becom popular sinc store handl big data effici compar relat databas relat databas graph databas advantag disadvantag overcom limit combin make hybrid model paper discuss relat databas graph databas advantag applic also talk hybrid model  \n",
            "better report studi artifici intellig consort-ai beyond increas number studi artifici intellig ai publish dental oral scienc report also aspect studi suffer rang limit standard toward report like recent publish consolid standard report trial consort -ai extens help improv studi emerg field journal dental research jdr encourag author review reader adher standard notabl though wide rang aspect beyond report locat along variou step ai lifecycl consid conceiv conduct report evalu studi ai dentistri  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#5. Check most frequent words - candidates to add to the stopword list\n",
        "listofall = [ item for elem in stemmed_tokens_list for item in elem]\n",
        "\n",
        "freq = FreqDist(listofall)\n",
        "wnum=freq.B()\n",
        "print(\"\\nMost common words (total %d)\"%wnum)\n",
        "print(freq.most_common(30))"
      ],
      "metadata": {
        "id": "sFF6p-zEbKM6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7bd1263-501a-45e4-b19b-48f1f7d02e66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Most common words (total 10259)\n",
            "[('use', 1793), ('data', 1238), ('system', 1208), ('propos', 1082), ('model', 937), ('method', 880), ('comput', 868), ('robot', 806), ('imag', 792), ('perform', 774), ('base', 728), ('algorithm', 719), ('databas', 701), ('result', 685), ('secur', 665), ('paper', 635), ('approach', 621), ('compil', 602), ('applic', 594), ('design', 569), ('gener', 548), ('learn', 543), ('develop', 535), ('detect', 513), ('process', 512), ('.', 512), ('inform', 507), ('network', 505), ('present', 504), ('implement', 481)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now remove stopwords like use, data, system as they appear after the stemming. We remove the top 30 common words, which contribute little meanings to the research title's focus."
      ],
      "metadata": {
        "id": "dFxMiP4N9WSb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'freq' is your FreqDist object and 'stemmed_tokens_list' is your list of lists of tokens\n",
        "most_common_words = [word for word, freq in freq.most_common(30)]\n",
        "\n",
        "# Convert the list to a set for faster membership testing\n",
        "common_words_set = set(most_common_words)\n",
        "\n",
        "# Now filter out these common words from the stemmed tokens\n",
        "filtered_tokens_list = [[token for token in tokens if token not in common_words_set] for tokens in stemmed_tokens_list]\n",
        "\n",
        "#5. Check most frequent words - candidates to add to the stopword list\n",
        "listofall = [ item for elem in filtered_tokens_list for item in elem]\n",
        "\n",
        "freq_filtered = FreqDist(listofall)\n",
        "wnum=freq_filtered.B()\n",
        "print(\"\\nMost common words after filtering (total %d)\"%wnum)\n",
        "print(freq_filtered.most_common(30))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYMLa1qQ3l1c",
        "outputId": "afbcf1d5-3115-4641-9765-236bc495a359"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Most common words after filtering (total 10229)\n",
            "[('differ', 470), ('improv', 445), ('relat', 445), ('provid', 441), ('show', 437), ('optim', 437), ('techniqu', 430), ('time', 429), ('studi', 417), ('program', 417), ('evalu', 386), ('also', 385), ('effici', 380), ('work', 375), ('problem', 366), ('analysi', 365), ('object', 361), ('scheme', 358), ('research', 349), ('new', 348), ('featur', 347), ('control', 337), ('key', 336), ('structur', 333), ('compar', 332), ('requir', 331), ('vision', 327), ('two', 324), ('task', 320), ('framework', 316)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. K-means clustering and topic detection**"
      ],
      "metadata": {
        "id": "QB2hbQd2_-5o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(b) Cluster the preprocessed data with $K$-means trying $K = 3, . . . , 10$.\n",
        "Evaluate the clustering quality with the Davies-Bouldin index and select the best K. Then evaluate the most frequent unigrams and most\n",
        "frequent bigrams in each cluster. (It is possible that the lists still contain some uninformative stopwords that you need to exclude.) Try to\n",
        "conclude what is the topic of each cluster. This is the baseline solution,\n",
        "so don’t worry, if all the topics are not yet clear."
      ],
      "metadata": {
        "id": "g9MkUaPSCSxf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Report here the results of the K-means approach. What was the best clustering (K\n",
        "and Davies-Bouldin index), the most frequent unigrams and bigrams\n",
        "in clusters (e.g., in a table), and your conclusion on the topics."
      ],
      "metadata": {
        "id": "__DaRPkSB69Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we proceed to add unigram, bigram and both grams tf-idf models"
      ],
      "metadata": {
        "id": "3dzh13Yd-m2K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#6. Present as tf-idf\n",
        "cleaned_documents = [' '.join(sentence_tokens) for sentence_tokens in filtered_tokens_list]\n",
        "\n",
        "# copy of clean_documents for part (c) SVD\n",
        "SVD_cleaned_documents = deepcopy(cleaned_documents)\n",
        "\n",
        "print('The preprocessed clean documents:')\n",
        "for document in cleaned_documents[:10]:\n",
        "\tprint(document)"
      ],
      "metadata": {
        "id": "J3jgBlQybPQX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c51eddf3-22ec-4402-d259-55cc5502c203"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The preprocessed clean documents:\n",
            "anomali wide area imageri geniş alan görüntülerind anomali tespiti studi anomali wide area imageri collect aircraft set anomali identifi anyth normal cours action purpos two differ set experi carri set anomali convolut neural tri next past pre-process given anomali compar estim true\n",
            "person re-identif deep kronecker-product match group-shuffl random walk person re-identif re-id aim robustli measur visual affin person wide intellig surveil associ person across multipl camera treat retriev problem given probe person affin probe galleri pg affin rank retriev galleri exist two main challeng effect solv problem person usual show signific variat differ person pose view angl spatial layout correspond person therefor vital tackl problem state-of-the-art either ignor spatial variat util extra pose handl challeng exist person re-id rank galleri consid pg affin ignor affin galleri gg affin affin could provid import clue accur galleri rank util post-process stage current articl unifi end-to-end deep framework tackl two challeng handl viewpoint pose variat compar person novel kroneck product match oper match warp featur map differ person compar warp featur map accur pg affin fulli util avail pg gg affin accur rank galleri person novel group-shuffl random walk oper kroneck product match group-shuffl random walk oper end-to-end trainabl shown improv visual featur integr deep framework outperform state-of-the-art market- cuhk dukemtmc dataset demonstr effect abil code avail http //github.com/yantaoshen/kpm_rw_person_reid\n",
            "crack masonri cnn signific bodi research crack vision concret asphalt less attent given masonri train convolut neural cnn brick wall built laboratori environ test abil crack brick-and-mortar structur laboratori real-world taken internet also compar cnn varieti simpler classifi oper handcraft featur find cnn better domain adapt laboratori real-world simpl howev also find significantli better revers domain adapt task simpl classifi train real-world test laboratori work demonstr abil crack masonri varieti machin provid guidanc improv reliabl domain adapt crack masonri\n",
            "toward energi effici code mobil phone smartphon becom part everyday life last year devic help us mani area life sport job weather etc sometim also annoy batteri life time import find solut reduc energi consumpt smartphon one possibl 'comput offload part execut remot devic e.g cloud lot exampl alreadi shown offload reduc energi usag mobil devic howev amount energi save may differ decis make offload control sever techniqu decis make theori schedul theori go introduc new call ecgm energi effici code mobil phone ecgm decid automat time task run smartphon task offload benefit demonstr measur energy-effici schedul techniqu\n",
            "sub-polyhedr schedul unit- two-variable-per-inequ polyhedra polyhedr success complex loop nest optim parallel complex scalabl limit remain one import weak address sub-polyhedr under-aproxim constraint affin schedul problem sub-polyhedr schedul techniqu unit- two-variable-per-inequ u tvpi polyhedra techniqu reli simpl polynomi time under-approxim polyhedron u tvpi polyhedra modifi state-of-the-art pluto schedul techniqu show major polybench kernel under-approxim yield polyhedra non-empti solv under-approxim lead asymptot gain complex show practic signific improv compar tradit lp solver also verifi code sub-polyhedr parallel prototyp match pluto-optim code under-approxim preserv feasibl copyright\n",
            "extract multipl viewpoint relat much time mine project spent find understand sourc extract event need fraction time spent actual appli techniqu discov control predict busi moreov current mine techniqu assum singl case notion howev real-lif often differ case notion intertwin exampl event order handl may refer custom order order line deliveri payment therefor multipl viewpoint mvp relat event object relat activ class requir event much closer exist relat mvp provid holist view also allow extract classic event log differ viewpoint way exist mine techniqu viewpoint without need new extract transform provid toolchain allow discoveri mvp annot frequenc relat moreov demonstr classic mine techniqu appli select viewpoint\n",
            "program checker lexic analysi gnu c theori program check establish well-suit construct formal correct frontend never prove practic real-lif proof necessari establish check choic correctli show lexic analysi gnu c formal specifi check within theorem prover isabelle/hol util program check therebi demonstr formal specif verif techniqu abl handl real-lif\n",
            "advanc visual object track correl filter 基于相关滤波的视觉目标跟踪算法新进展 excel comprehens correl filter-bas track becom hotspot theoret research practic field visual object track despit mani studi still lack systemat analys exist correl filter-bas track level track framework therefor start basic framework object track characterist correl filter-bas track deepli analyz basic problem work stage basi main technolog progress correl filter-bas track characterist correspond recent ten year summar typic correl filter-bas track evalu analyz final outstand issu urgent solv futur research direct correl filter-bas track discuss\n",
            "studi variou relat graph hybrid relat popular store variou type due ever-increas growth becom hard maintain graph becom popular sinc store handl big effici compar relat relat graph advantag disadvantag overcom limit combin make hybrid discuss relat graph advantag also talk hybrid\n",
            "better report studi artifici intellig consort-ai beyond increas number studi artifici intellig ai publish dental oral scienc report also aspect studi suffer rang limit standard toward report like recent publish consolid standard report trial consort -ai extens help improv studi emerg field journal dental research jdr encourag author review reader adher standard notabl though wide rang aspect beyond report locat along variou step ai lifecycl consid conceiv conduct report evalu studi ai dentistri\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Unigram tf-idf vectorizer"
      ],
      "metadata": {
        "id": "ZEA3ykLYEc7r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ignoring terms that appear in less than 5% of the documents or in more than 25% of the documents\n",
        "\n",
        "unigram_tfidf_vectorizer = TfidfVectorizer(\n",
        "    min_df=0.05,\n",
        "    max_df=0.25,\n",
        "    smooth_idf=False,\n",
        "    norm='l2',            # Ensures all our feature vectors have a euclidian norm of 1\n",
        "    ngram_range=(1,1)     # Extract only unigrams\n",
        ")\n",
        "\n",
        "#only tf part:\n",
        "#tfidf_vectorizer = TfidfVectorizer(use_idf=False)\n",
        "\n",
        "unigram_tfidf_vectorizer.fit(cleaned_documents)\n",
        "unigram_tf_idf_vectors = unigram_tfidf_vectorizer.transform(cleaned_documents)\n",
        "\n",
        "print(\"\\nThe shape of the tf-idf vectors (number of documents, number of features) for unigram model is\")\n",
        "print(unigram_tf_idf_vectors.shape)\n",
        "\n",
        "\n",
        "print(\"\\nThe tf-idf values of the first document (unigrams)\\n\")\n",
        "feature_names = unigram_tfidf_vectorizer.get_feature_names_out()\n",
        "feature_index = unigram_tf_idf_vectors[0,:].nonzero()[1]\n",
        "tfidf_scores = zip(feature_index, [unigram_tf_idf_vectors[0, x] for x in feature_index])\n",
        "for w, s in [(feature_names[i], s) for (i, s) in tfidf_scores]:\n",
        "    print(w, s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldnWsdlZB4QT",
        "outputId": "b5f45586-c836-4538-c26a-ac818d941d6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "The shape of the tf-idf vectors (number of documents, number of features) for unigram model is\n",
            "(1143, 349)\n",
            "\n",
            "The tf-idf values of the first document (unigrams)\n",
            "\n",
            "wide 0.42706672027885506\n",
            "two 0.14821467742261452\n",
            "studi 0.14557646252298534\n",
            "set 0.4974544721165923\n",
            "purpos 0.2292533250306582\n",
            "neural 0.1984329905770054\n",
            "identifi 0.20727323621885707\n",
            "given 0.22354864669609772\n",
            "experi 0.16858331667935514\n",
            "estim 0.21095129460311848\n",
            "convolut 0.2176249810162788\n",
            "compar 0.14710144650586116\n",
            "collect 0.22125896429309003\n",
            "area 0.3889064878787454\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bigram tf-idf vectorizer"
      ],
      "metadata": {
        "id": "CL_UoghpEgfr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ignoring terms that appear in less than 1.5% of the documents or in more than 25% of the documents\n",
        "# This min df relaxation compared to unigram mode helps more bigrams to be considered in the vectorizer\n",
        "\n",
        "bigram_tfidf_vectorizer = TfidfVectorizer(\n",
        "    min_df=0.015,\n",
        "    max_df=0.25,\n",
        "    smooth_idf=False,\n",
        "    norm='l2',            # Ensures all our feature vectors have a euclidian norm of 1\n",
        "    ngram_range=(2,2)     # Extract only bigrams\n",
        ")\n",
        "\n",
        "\n",
        "bigram_tfidf_vectorizer.fit(cleaned_documents)\n",
        "bigram_tf_idf_vectors = bigram_tfidf_vectorizer.transform(cleaned_documents)\n",
        "\n",
        "print(\"\\nThe shape of the tf-idf vectors (number of documents, number of features) for bigram model is\")\n",
        "print(bigram_tf_idf_vectors.shape)\n",
        "\n",
        "\n",
        "print(\"\\nThe tf-idf values of the first document (bigrams)\\n\")\n",
        "feature_names = bigram_tfidf_vectorizer.get_feature_names_out()\n",
        "feature_index = bigram_tf_idf_vectors[0,:].nonzero()[1]\n",
        "tfidf_scores = zip(feature_index, [bigram_tf_idf_vectors[0, x] for x in feature_index])\n",
        "for w, s in [(feature_names[i], s) for (i, s) in tfidf_scores]:\n",
        "    print(w, s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kdd39BcwB44D",
        "outputId": "b812f48f-39ef-402e-ddef-16b7b1663939"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "The shape of the tf-idf vectors (number of documents, number of features) for bigram model is\n",
            "(1143, 50)\n",
            "\n",
            "The tf-idf values of the first document (bigrams)\n",
            "\n",
            "two differ 0.7839204046175395\n",
            "convolut neural 0.6208613365513053\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Both grams tf-idf vectorizer"
      ],
      "metadata": {
        "id": "8UAqcafKEina"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ignoring terms that appear in less than 0.5% of the documents or in more than 50% of the documents\n",
        "# The very small min_df accounts for the explosion of terms caused by bigrams\n",
        "\n",
        "both_tfidf_vectorizer = TfidfVectorizer(\n",
        "    min_df=0.005,\n",
        "    max_df=0.25,\n",
        "    smooth_idf=False,\n",
        "    norm='l2',            # Ensures all our feature vectors have a euclidian norm of 1\n",
        "    ngram_range=(1,2)     # Extract only both unigrams and bigrams\n",
        ")\n",
        "\n",
        "\n",
        "both_tfidf_vectorizer.fit(cleaned_documents)\n",
        "both_tf_idf_vectors = both_tfidf_vectorizer.transform(cleaned_documents)\n",
        "\n",
        "print(\"\\nThe shape of the tf-idf vectors (number of documents, number of features) for both grams model is\")\n",
        "print(both_tf_idf_vectors.shape)\n",
        "\n",
        "\n",
        "print(\"\\nThe tf-idf values of the first document (both grams)\\n\")\n",
        "feature_names = both_tfidf_vectorizer.get_feature_names_out()\n",
        "feature_index = both_tf_idf_vectors[0,:].nonzero()[1]\n",
        "tfidf_scores = zip(feature_index, [both_tf_idf_vectors[0, x] for x in feature_index])\n",
        "for w, s in [(feature_names[i], s) for (i, s) in tfidf_scores]:\n",
        "    print(w, s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EfgxbDL7EKXL",
        "outputId": "1b7ae9cf-6dd5-4d0a-d480-bd97a7b004eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "The shape of the tf-idf vectors (number of documents, number of features) for both grams model is\n",
            "(1143, 2619)\n",
            "\n",
            "The tf-idf values of the first document (both grams)\n",
            "\n",
            "wide 0.1655509884341766\n",
            "two differ 0.11437782918690984\n",
            "two 0.057454924916052634\n",
            "true 0.12705410179616836\n",
            "tri 0.12248788556946724\n",
            "studi 0.056432229717395616\n",
            "set 0.19283656545780464\n",
            "purpos 0.08886928612902774\n",
            "process 0.11751825835945813\n",
            "pre process 0.14698109324214143\n",
            "pre 0.10688834399803271\n",
            "past 0.11341776593920974\n",
            "normal 0.10121662633184234\n",
            "next 0.11987204952994096\n",
            "neural 0.07692188636595902\n",
            "imageri 0.24782734524724012\n",
            "identifi 0.08034877807752544\n",
            "given 0.08665788661663103\n",
            "experi 0.06535075992705697\n",
            "estim 0.08177456513167825\n",
            "cours 0.10912987584470467\n",
            "convolut neural 0.09058671197041691\n",
            "convolut 0.08436159739089297\n",
            "compar 0.05702338466748522\n",
            "collect 0.08577029887677916\n",
            "carri 0.09619373005334125\n",
            "area 0.15075830173503266\n",
            "anomali 0.772781964651437\n",
            "aircraft 0.14335573382378414\n",
            "action 0.11249536208095705\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Clustering with K-means for the three n-grams model"
      ],
      "metadata": {
        "id": "Uy45-KM2FJb7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clustering the documents based on unigram tf-idf vectorizer\n",
        "\n",
        "min_score = 1e6\n",
        "best_k = 0\n",
        "for i in range(3,11):\n",
        "    kmeans = KMeans(n_clusters=i, n_init=20)\n",
        "    kmeans.fit(unigram_tf_idf_vectors)\n",
        "    labels = kmeans.labels_\n",
        "    db_index = davies_bouldin_score(unigram_tf_idf_vectors.toarray(), labels)\n",
        "    if db_index < min_score:\n",
        "        min_score = db_index\n",
        "        best_k = i\n",
        "\n",
        "print(\"Optimal number of clusters of the unigram model:\", best_k)\n",
        "print(\"Davies-Bouldin Index of the unigram model:\", min_score, \"\\n\")\n",
        "kmeans = KMeans(n_clusters=best_k, n_init=10)\n",
        "kmeans.fit(unigram_tf_idf_vectors)\n",
        "labels = kmeans.labels_\n",
        "db_index = davies_bouldin_score(unigram_tf_idf_vectors.toarray(), labels)\n",
        "\n",
        "clusters = {i: [] for i in range(best_k)}\n",
        "\n",
        "for point, label in zip(filtered_tokens_list, labels):\n",
        "    clusters[label].append(point)\n",
        "\n",
        "for i in range(best_k):\n",
        "    listofcluster = [ item for elem in clusters[i] for item in elem]\n",
        "    cluster_freq = FreqDist(listofcluster)\n",
        "    print(\"Cluster \", i, \":\", cluster_freq.most_common(15))"
      ],
      "metadata": {
        "id": "RLtNUOtPblPB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e6efc04-6c15-4b78-f721-2c1c45534d43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal number of clusters of the unigram model: 10\n",
            "Davies-Bouldin Index of the unigram model: 4.744800668411147 \n",
            "\n",
            "Cluster  0 : [('encrypt', 292), ('scheme', 271), ('key', 194), ('attack', 163), ('cryptographi', 156), ('protocol', 148), ('authent', 121), ('cloud', 108), ('provid', 97), ('iot', 93), ('effici', 86), ('cryptograph', 75), ('new', 72), ('devic', 72), ('techniqu', 71)]\n",
            "Cluster  1 : [('dataset', 180), ('train', 153), ('deep', 130), ('neural', 122), ('featur', 118), ('accuraci', 112), ('segment', 102), ('differ', 97), ('improv', 95), ('predict', 94), ('convolut', 89), ('achiev', 85), ('classif', 77), ('evalu', 75), ('show', 71)]\n",
            "Cluster  2 : [('quantum', 246), ('cryptographi', 52), ('key', 45), ('protocol', 40), ('attack', 37), ('oper', 35), ('post-quantum', 31), ('state', 31), ('commun', 31), ('gate', 29), ('scheme', 28), ('time', 27), ('circuit', 27), ('architectur', 26), ('also', 25)]\n",
            "Cluster  3 : [('vision', 186), ('video', 151), ('technolog', 115), ('research', 88), ('studi', 81), ('review', 75), ('techniqu', 72), ('recognit', 61), ('work', 60), ('analysi', 59), ('visual', 59), ('provid', 56), ('monitor', 56), ('structur', 55), ('deep', 53)]\n",
            "Cluster  4 : [('control', 218), ('measur', 154), ('estim', 75), ('sensor', 74), ('environ', 72), ('studi', 67), ('differ', 61), ('task', 58), ('simul', 55), ('effect', 52), ('optim', 51), ('motion', 51), ('dynam', 50), ('improv', 46), ('speed', 45)]\n",
            "Cluster  5 : [('provid', 118), ('studi', 112), ('task', 106), ('integr', 100), ('relat', 98), ('differ', 95), ('test', 94), ('construct', 94), ('research', 93), ('optim', 93), ('work', 91), ('oper', 91), ('time', 90), ('also', 89), ('evalu', 89)]\n",
            "Cluster  6 : [('queri', 237), ('relat', 234), ('sql', 59), ('store', 48), ('graph', 45), ('effici', 44), ('user', 44), ('languag', 39), ('time', 37), ('ontolog', 37), ('manag', 36), ('schema', 35), ('differ', 34), ('optim', 33), ('structur', 32)]\n",
            "Cluster  7 : [('program', 204), ('code', 172), ('optim', 142), ('graph', 139), ('memori', 128), ('parallel', 122), ('transform', 92), ('time', 77), ('techniqu', 76), ('regist', 73), ('problem', 64), ('show', 61), ('new', 60), ('alloc', 57), ('execut', 56)]\n",
            "Cluster  8 : [('object', 214), ('track', 129), ('featur', 45), ('evalu', 36), ('accuraci', 35), ('improv', 33), ('challeng', 32), ('show', 31), ('visual', 30), ('train', 30), ('differ', 27), ('deep', 27), ('filter', 26), ('research', 26), ('howev', 26)]\n",
            "Cluster  9 : [('languag', 183), ('program', 105), ('semant', 53), ('type', 44), ('proof', 35), ('transform', 33), ('framework', 33), ('construct', 30), ('theori', 29), ('formal', 26), (\"'s\", 25), ('teach', 24), ('softwar', 23), ('verifi', 23), ('code', 22)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clustering the documents based on bigram tf-idf vectorizer\n",
        "\n",
        "min_score = 1e6\n",
        "best_k = 0\n",
        "for i in range(3,11):\n",
        "    kmeans = KMeans(n_clusters=i, n_init=20)\n",
        "    kmeans.fit(bigram_tf_idf_vectors)\n",
        "    labels = kmeans.labels_\n",
        "    db_index = davies_bouldin_score(bigram_tf_idf_vectors.toarray(), labels)\n",
        "    if db_index < min_score:\n",
        "        min_score = db_index\n",
        "        best_k = i\n",
        "\n",
        "print(\"Optimal number of clusters of the bigram model:\", best_k)\n",
        "print(\"Davies-Bouldin Index of the bigram model:\", min_score, \"\\n\")\n",
        "\n",
        "# Fit the KMeans model to find the best_k clusters\n",
        "kmeans = KMeans(n_clusters=best_k, n_init=20)\n",
        "kmeans.fit(bigram_tf_idf_vectors)\n",
        "labels = kmeans.labels_\n",
        "\n",
        "# Extract the top bigrams for each cluster center\n",
        "feature_names = bigram_tfidf_vectorizer.get_feature_names_out()\n",
        "\n",
        "for i in range(best_k):\n",
        "    # Get indices of the top features for this cluster\n",
        "    top_feature_indices = kmeans.cluster_centers_[i].argsort()[-10:][::-1]\n",
        "\n",
        "    print(f\"Cluster {i} and bigram TF-IDF score:\", end=\" \")\n",
        "    for idx in top_feature_indices:\n",
        "        print(f\"({feature_names[idx]}: {kmeans.cluster_centers_[i][idx]:.4f})\", end=\", \")\n",
        "    print(\"\\n\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bs6VE0dmIXcX",
        "outputId": "2e25c5ca-f4ab-48e0-9204-e42f5024ede5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal number of clusters of the bigram model: 8\n",
            "Davies-Bouldin Index of the bigram model: 1.2864844842709722 \n",
            "\n",
            "Cluster 0 and bigram TF-IDF score: (program languag: 0.0270), (real world: 0.0254), (experiment show: 0.0249), (recent year: 0.0233), (execut time: 0.0222), (open sourc: 0.0215), (time consum: 0.0185), (two differ: 0.0184), (well known: 0.0181), (solv problem: 0.0181), \n",
            "\n",
            "Cluster 1 and bigram TF-IDF score: (convolut neural: 0.6531), (neural cnn: 0.2571), (artifici intellig: 0.0784), (experiment show: 0.0687), (time consum: 0.0337), (learning bas: 0.0271), (end to: 0.0268), (to end: 0.0268), (open sourc: 0.0261), (solv problem: 0.0259), \n",
            "\n",
            "Cluster 2 and bigram TF-IDF score: (vision bas: 0.7797), (three dimension: 0.0660), (improv accuraci: 0.0590), (real world: 0.0561), (futur research: 0.0440), (wide rang: 0.0392), (low cost: 0.0385), (real tim: 0.0369), (learning bas: 0.0353), (convolut neural: 0.0321), \n",
            "\n",
            "Cluster 3 and bigram TF-IDF score: (case studi: 0.9006), (et al: 0.0453), (experi conduct: 0.0227), (three dimension: 0.0227), (two differ: 0.0222), (time consum: 0.0217), (real world: 0.0210), (secret key: 0.0190), (deep learning: 0.0186), (learning bas: 0.0164), \n",
            "\n",
            "Cluster 4 and bigram TF-IDF score: (high level: 0.8721), (program languag: 0.1285), (convolut neural: 0.0326), (experi conduct: 0.0214), (high perform: 0.0212), (large scal: 0.0209), (case studi: 0.0196), (recent advanc: 0.0185), (wide rang: 0.0173), (internet thing: 0.0160), \n",
            "\n",
            "Cluster 5 and bigram TF-IDF score: (state of: 0.4422), (of the: 0.4331), (the art: 0.4312), (learning bas: 0.0591), (real world: 0.0527), (deep learning: 0.0395), (experiment show: 0.0386), (artifici intellig: 0.0348), (convolut neural: 0.0343), (futur research: 0.0326), \n",
            "\n",
            "Cluster 6 and bigram TF-IDF score: (ellipt curv: 0.6534), (curv cryptographi: 0.4573), (public key: 0.0833), (low cost: 0.0699), (internet thing: 0.0610), (secret key: 0.0515), (et al: 0.0513), (thing iot: 0.0484), (key cryptographi: 0.0463), (key encrypt: 0.0359), \n",
            "\n",
            "Cluster 7 and bigram TF-IDF score: (real tim: 0.8296), (state of: 0.0456), (solv problem: 0.0400), (real time: 0.0386), (experiment show: 0.0381), (the art: 0.0325), (of the: 0.0321), (power consumpt: 0.0300), (execut time: 0.0287), (convolut neural: 0.0192), \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clustering the documents based on bigram tf-idf vectorizer\n",
        "\n",
        "min_score = 1e6\n",
        "best_k = 0\n",
        "for i in range(3,11):\n",
        "    kmeans = KMeans(n_clusters=i, n_init=20)\n",
        "    kmeans.fit(both_tf_idf_vectors)\n",
        "    labels = kmeans.labels_\n",
        "    db_index = davies_bouldin_score(both_tf_idf_vectors.toarray(), labels)\n",
        "    if db_index < min_score:\n",
        "        min_score = db_index\n",
        "        best_k = i\n",
        "\n",
        "print(\"Optimal number of clusters of the both grams model:\", best_k)\n",
        "print(\"Davies-Bouldin Index of the both grams model:\", min_score, \"\\n\")\n",
        "\n",
        "# Assuming 'both_tf_idf_vectors' is your TF-IDF matrix and 'both_tfidf_vectorizer' is the vectorizer used to create it\n",
        "\n",
        "# Fit the KMeans model to find the best_k clusters\n",
        "kmeans = KMeans(n_clusters=best_k, n_init=20)\n",
        "kmeans.fit(both_tf_idf_vectors)\n",
        "labels = kmeans.labels_\n",
        "\n",
        "# Extract the top bigrams for each cluster center\n",
        "feature_names = both_tfidf_vectorizer.get_feature_names_out()\n",
        "\n",
        "for i in range(best_k):\n",
        "    # Get indices of the top features for this cluster\n",
        "    top_feature_indices = kmeans.cluster_centers_[i].argsort()[-10:][::-1]\n",
        "\n",
        "    print(f\"Cluster {i} and TF-IDF score:\", end=\" \")\n",
        "    for idx in top_feature_indices:\n",
        "        print(f\"({feature_names[idx]}: {kmeans.cluster_centers_[i][idx]:.4f})\", end=\", \")\n",
        "    print(\"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cCvVpQkVl3b",
        "outputId": "e84b92a0-a44a-4ae6-fa4f-c872db4dcb44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal number of clusters of the both grams model: 5\n",
            "Davies-Bouldin Index of the both grams model: 6.968635009292602 \n",
            "\n",
            "Cluster 0 and TF-IDF score: (quantum: 0.4007), (gate: 0.0624), (key: 0.0573), (cryptographi: 0.0559), (qubit: 0.0554), (protocol: 0.0540), (circuit: 0.0473), (post quantum: 0.0465), (attack: 0.0428), (post: 0.0413), \n",
            "\n",
            "Cluster 1 and TF-IDF score: (encrypt: 0.0940), (scheme: 0.0708), (cryptographi: 0.0548), (key: 0.0536), (attack: 0.0522), (iot: 0.0482), (protocol: 0.0476), (cloud: 0.0407), (authent: 0.0407), (cryptograph: 0.0354), \n",
            "\n",
            "Cluster 2 and TF-IDF score: (relat: 0.0467), (program: 0.0453), (queri: 0.0451), (languag: 0.0449), (graph: 0.0366), (code: 0.0340), (optim: 0.0288), (transform: 0.0243), (sql: 0.0242), (memori: 0.0239), \n",
            "\n",
            "Cluster 3 and TF-IDF score: (control: 0.0575), (measur: 0.0395), (soft: 0.0361), (sensor: 0.0303), (estim: 0.0287), (environ: 0.0275), (task: 0.0271), (simul: 0.0251), (human: 0.0240), (optim: 0.0221), \n",
            "\n",
            "Cluster 4 and TF-IDF score: (vision: 0.0407), (object: 0.0403), (deep: 0.0361), (dataset: 0.0307), (video: 0.0307), (featur: 0.0298), (track: 0.0288), (accuraci: 0.0273), (train: 0.0268), (segment: 0.0261), \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Therefore, the baseline solution seems to have 5 topics:\n",
        "\n",
        "- Topic 1: Database, SQL and queries\n",
        "- Topic 2: General programming and operating system/hardware\n",
        "- Topic 3: Computer vision and robotics\n",
        "- Topic 4: Security and cryptography\n",
        "- Topic 5: Quantum studies and application in security"
      ],
      "metadata": {
        "id": "clDXgcb0Zj9_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3. Additional experiments**"
      ],
      "metadata": {
        "id": "_3VO77WJ__K_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(c) Try to improve your results! Here you can freely try any methods covered in the course. You can improve the preprocessing (e.g., lemmatization), clustering (e.g., try dimension reduction or another clustering method) or the evaluation of the most important terms (e.g., utilize\n",
        "the title, perform SVD per cluster and look at the leading singular\n",
        "vector or analyze only the centroid or most central documents). Conclude the main (3–10) topics of the document collection based on your experiments!"
      ],
      "metadata": {
        "id": "kybHA50QCWO2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Report here your experiments in the (c) part. Describe briefly what you tried and the results (the most important terms and concluded topics). Evaluate also if your experiment was successful, i.e., if it produced better results than the\n",
        "baseline. It is suggested to divide this section into subsections, if you\n",
        "tried many approaches."
      ],
      "metadata": {
        "id": "RQySxMZ0B_ho"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Experiment with only the title (unigram tf-idf vectorizer)"
      ],
      "metadata": {
        "id": "74PIMTT5GWDi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "titledata = scopusdata['TITLE'].to_list()\n",
        "\n",
        "title_tokens = [word_tokenize(document) for document in corpus]\n",
        "\n",
        "title_lc_tokens_list = []\n",
        "\n",
        "for token_document in title_tokens:\n",
        "    title_lc_tokens_list.append([token.lower() for token in token_document])\n",
        "\n",
        "\n",
        "# original number of tokens\n",
        "uniques = np.unique([token for token_document in title_lc_tokens_list for token in token_document])\n",
        "\n",
        "\n",
        "\n",
        "# Steps 2 and 3: remove stop words and punctuation\n",
        "\n",
        "title_filtered_sentence = []\n",
        "for i in title_lc_tokens_list:\n",
        "    title_filtered_sentence.append([token for token in i if token not in stop_words])\n",
        "\n",
        "# Numbers are also removed\n",
        "title_filtered_sentence = [ ' '.join(i) for i in title_filtered_sentence ]\n",
        "title_filtered_sentence = [ re.sub(r'\\d+', '', sentence) for sentence in title_filtered_sentence ]\n",
        "\n",
        "# Step 4 Stemming\n",
        "title_stemmed_tokens_list = []\n",
        "\n",
        "for i in title_filtered_sentence:\n",
        "\ttitle_stemmed_tokens_list.append([porter.stem(j) for j in i.split()])\n",
        "\n",
        "title_filtered_tokens_list = [[token for token in tokens if token not in common_words_set] for tokens in title_stemmed_tokens_list]\n",
        "\n",
        "#6. Present as tf-idf\n",
        "title_cleaned_documents = [' '.join(sentence_tokens) for sentence_tokens in title_filtered_tokens_list]\n",
        "\n",
        "\n",
        "unigram_tfidf_vectorizer = TfidfVectorizer(\n",
        "    min_df=0.05,\n",
        "    max_df=0.25,\n",
        "    smooth_idf=False,\n",
        "    norm='l2',            # Ensures all our feature vectors have a euclidian norm of 1\n",
        "    ngram_range=(1,1)     # Extract only unigrams\n",
        ")\n",
        "unigram_tfidf_vectorizer.fit(title_cleaned_documents)\n",
        "title_unigram_tf_idf_vectors = unigram_tfidf_vectorizer.transform(title_cleaned_documents)\n",
        "\n",
        "feature_names = unigram_tfidf_vectorizer.get_feature_names_out()\n",
        "feature_index = title_unigram_tf_idf_vectors[0,:].nonzero()[1]\n",
        "tfidf_scores = zip(feature_index, [title_unigram_tf_idf_vectors[0, x] for x in feature_index])\n"
      ],
      "metadata": {
        "id": "pI9g8ZJbah2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clustering the documents based on unigram tf-idf vectorizer\n",
        "\n",
        "min_score = 1e6\n",
        "best_k = 0\n",
        "for i in range(3,11):\n",
        "    kmeans = KMeans(n_clusters=i, n_init=20)\n",
        "    kmeans.fit(unigram_tf_idf_vectors)\n",
        "    labels = kmeans.labels_\n",
        "    db_index = davies_bouldin_score(title_unigram_tf_idf_vectors.toarray(), labels)\n",
        "    if db_index < min_score:\n",
        "        min_score = db_index\n",
        "        best_k = i\n",
        "\n",
        "print(\"Optimal number of clusters of the unigram model:\", best_k)\n",
        "print(\"Davies-Bouldin Index of the unigram model:\", min_score, \"\\n\")\n",
        "kmeans = KMeans(n_clusters=best_k, n_init=10)\n",
        "kmeans.fit(title_unigram_tf_idf_vectors)\n",
        "labels = kmeans.labels_\n",
        "db_index = davies_bouldin_score(title_unigram_tf_idf_vectors.toarray(), labels)\n",
        "\n",
        "clusters = {i: [] for i in range(best_k)}\n",
        "\n",
        "for point, label in zip(filtered_tokens_list, labels):\n",
        "    clusters[label].append(point)\n",
        "\n",
        "for i in range(best_k):\n",
        "    listofcluster = [ item for elem in clusters[i] for item in elem]\n",
        "    cluster_freq = FreqDist(listofcluster)\n",
        "    print(\"Cluster \", i, \":\", cluster_freq.most_common(15))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjZYbuW13aVi",
        "outputId": "a7dab38b-5114-4452-f379-87b83117cbb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal number of clusters of the unigram model: 5\n",
            "Davies-Bouldin Index of the unigram model: 4.841051642953007 \n",
            "\n",
            "Cluster  0 : [('vision', 286), ('object', 276), ('dataset', 220), ('deep', 219), ('featur', 205), ('train', 204), ('video', 187), ('accuraci', 186), ('visual', 169), ('track', 166), ('differ', 165), ('neural', 160), ('research', 159), ('studi', 155), ('improv', 154)]\n",
            "Cluster  1 : [('program', 305), ('relat', 301), ('languag', 260), ('queri', 254), ('graph', 183), ('code', 179), ('transform', 129), ('type', 118), ('semant', 117), ('show', 104), ('optim', 102), ('analysi', 100), ('tool', 99), ('time', 97), ('parallel', 96)]\n",
            "Cluster  2 : [('quantum', 254), ('cryptographi', 54), ('key', 45), ('protocol', 40), ('oper', 39), ('attack', 39), ('scheme', 34), ('post-quantum', 33), ('state', 33), ('gate', 32), ('commun', 32), ('circuit', 32), ('program', 31), ('time', 31), ('also', 30)]\n",
            "Cluster  3 : [('encrypt', 292), ('scheme', 264), ('key', 194), ('attack', 161), ('cryptographi', 156), ('protocol', 148), ('authent', 122), ('cloud', 108), ('provid', 100), ('iot', 93), ('effici', 83), ('cryptograph', 75), ('techniqu', 73), ('new', 71), ('devic', 70)]\n",
            "Cluster  4 : [('control', 249), ('optim', 239), ('studi', 174), ('improv', 162), ('task', 161), ('differ', 154), ('time', 145), ('show', 143), ('provid', 133), ('also', 131), ('environ', 129), ('problem', 128), ('work', 128), ('oper', 127), ('increas', 126)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Therefore, the solution with only the title seems to have 5 topics (The order of the topics may randomly change each time the algorithm is run):\n",
        "\n",
        "- Topic 1: General programming and operating system/hardware\n",
        "- Topic 2: Quantum studies and application in security\n",
        "- Topic 3: Database, SQL and queries\n",
        "- Topic 4: Computer vision and robotics\n",
        "- Topic 5: Security and cryptography\n"
      ],
      "metadata": {
        "id": "s4jEd1CYeQBo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Experiment with lemmatization (unigram tf-idf vectorizer)"
      ],
      "metadata": {
        "id": "NxGSmPX_GKH7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def get_wordnet_pos(word):\n",
        "    \"\"\"Map POS tag to first character lemmatize() accepts.\"\"\"\n",
        "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
        "    tag_dict = {\"J\": wordnet.ADJ,\n",
        "                \"N\": wordnet.NOUN,\n",
        "                \"V\": wordnet.VERB,\n",
        "                \"R\": wordnet.ADV}\n",
        "\n",
        "    return tag_dict.get(tag, wordnet.NOUN)\n",
        "\n",
        "lemmatized_tokens_list = []\n",
        "\n",
        "lemmatized_tokens_list = [[lemmatizer.lemmatize(word, get_wordnet_pos(word)) for word in doc] for doc in filtered_tokens_list]\n",
        "cleaned = [' '.join(sentence_tokens) for sentence_tokens in lemmatized_tokens_list]\n",
        "\n",
        "print('The preprocessed clean documents:')\n",
        "for document in cleaned[:10]:\n",
        "\tprint(document)\n"
      ],
      "metadata": {
        "id": "lJEekpHTaiR2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcd15f6f-6b12-444d-89e3-850ebfd68dcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The preprocessed clean documents:\n",
            "anomali wide area imageri geniş alan görüntülerind anomali tespiti studi anomali wide area imageri collect aircraft set anomali identifi anyth normal cours action purpos two differ set experi carri set anomali convolut neural tri next past pre-process give anomali compar estim true\n",
            "person re-identif deep kronecker-product match group-shuffl random walk person re-identif re-id aim robustli measur visual affin person wide intellig surveil associ person across multipl camera treat retriev problem give probe person affin probe galleri pg affin rank retriev galleri exist two main challeng effect solv problem person usual show signific variat differ person pose view angl spatial layout correspond person therefor vital tackl problem state-of-the-art either ignor spatial variat util extra pose handl challeng exist person re-id rank galleri consid pg affin ignor affin galleri gg affin affin could provid import clue accur galleri rank util post-process stage current articl unifi end-to-end deep framework tackl two challeng handl viewpoint pose variat compar person novel kroneck product match oper match warp featur map differ person compar warp featur map accur pg affin fulli util avail pg gg affin accur rank galleri person novel group-shuffl random walk oper kroneck product match group-shuffl random walk oper end-to-end trainabl show improv visual featur integr deep framework outperform state-of-the-art market- cuhk dukemtmc dataset demonstr effect abil code avail http //github.com/yantaoshen/kpm_rw_person_reid\n",
            "crack masonri cnn signific bodi research crack vision concret asphalt less attent give masonri train convolut neural cnn brick wall built laboratori environ test abil crack brick-and-mortar structur laboratori real-world take internet also compar cnn varieti simpler classifi oper handcraft featur find cnn well domain adapt laboratori real-world simpl howev also find significantli well revers domain adapt task simpl classifi train real-world test laboratori work demonstr abil crack masonri varieti machin provid guidanc improv reliabl domain adapt crack masonri\n",
            "toward energi effici code mobil phone smartphon becom part everyday life last year devic help u mani area life sport job weather etc sometim also annoy batteri life time import find solut reduc energi consumpt smartphon one possibl 'comput offload part execut remot devic e.g cloud lot exampl alreadi show offload reduc energi usag mobil devic howev amount energi save may differ decis make offload control sever techniqu decis make theori schedul theori go introduc new call ecgm energi effici code mobil phone ecgm decid automat time task run smartphon task offload benefit demonstr measur energy-effici schedul techniqu\n",
            "sub-polyhedr schedul unit- two-variable-per-inequ polyhedron polyhedr success complex loop nest optim parallel complex scalabl limit remain one import weak address sub-polyhedr under-aproxim constraint affin schedul problem sub-polyhedr schedul techniqu unit- two-variable-per-inequ u tvpi polyhedron techniqu reli simpl polynomi time under-approxim polyhedron u tvpi polyhedron modifi state-of-the-art pluto schedul techniqu show major polybench kernel under-approxim yield polyhedron non-empti solv under-approxim lead asymptot gain complex show practic signific improv compar tradit lp solver also verifi code sub-polyhedr parallel prototyp match pluto-optim code under-approxim preserv feasibl copyright\n",
            "extract multipl viewpoint relat much time mine project spent find understand sourc extract event need fraction time spent actual appli techniqu discov control predict busi moreov current mine techniqu assum singl case notion howev real-lif often differ case notion intertwin exampl event order handl may refer custom order order line deliveri payment therefor multipl viewpoint mvp relat event object relat activ class requir event much closer exist relat mvp provid holist view also allow extract classic event log differ viewpoint way exist mine techniqu viewpoint without need new extract transform provid toolchain allow discoveri mvp annot frequenc relat moreov demonstr classic mine techniqu appli select viewpoint\n",
            "program checker lexic analysi gnu c theori program check establish well-suit construct formal correct frontend never prove practic real-lif proof necessari establish check choic correctli show lexic analysi gnu c formal specifi check within theorem prover isabelle/hol util program check therebi demonstr formal specif verif techniqu abl handl real-lif\n",
            "advanc visual object track correl filter 基于相关滤波的视觉目标跟踪算法新进展 excel comprehens correl filter-bas track becom hotspot theoret research practic field visual object track despit mani studi still lack systemat analys exist correl filter-bas track level track framework therefor start basic framework object track characterist correl filter-bas track deepli analyz basic problem work stage basi main technolog progress correl filter-bas track characterist correspond recent ten year summar typic correl filter-bas track evalu analyz final outstand issu urgent solv futur research direct correl filter-bas track discus\n",
            "studi variou relat graph hybrid relat popular store variou type due ever-increas growth becom hard maintain graph becom popular sinc store handl big effici compar relat relat graph advantag disadvantag overcom limit combin make hybrid discus relat graph advantag also talk hybrid\n",
            "well report studi artifici intellig consort-ai beyond increas number studi artifici intellig ai publish dental oral scienc report also aspect studi suffer rang limit standard toward report like recent publish consolid standard report trial consort -ai extens help improv studi emerg field journal dental research jdr encourag author review reader adher standard notabl though wide rang aspect beyond report locat along variou step ai lifecycl consid conceiv conduct report evalu studi ai dentistri\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unigram_tfidf_vectorizer = TfidfVectorizer(\n",
        "    min_df=0.05,\n",
        "    max_df=0.25,\n",
        "    smooth_idf=False,\n",
        "    norm='l2',            # Ensures all our feature vectors have a euclidian norm of 1\n",
        "    ngram_range=(1,1)     # Extract only unigrams\n",
        ")\n",
        "unigram_tfidf_vectorizer.fit(cleaned)\n",
        "lemmatized_unigram_tf_idf_vectors = unigram_tfidf_vectorizer.transform(cleaned)\n",
        "\n",
        "print(\"\\nThe shape of the tf-idf vectors (number of documents, number of features) for unigram model is\")\n",
        "print(lemmatized_unigram_tf_idf_vectors.shape)\n",
        "\n",
        "\n",
        "print(\"\\nThe tf-idf values of the first document (unigrams)\\n\")\n",
        "feature_names = unigram_tfidf_vectorizer.get_feature_names_out()\n",
        "feature_index = lemmatized_unigram_tf_idf_vectors[0,:].nonzero()[1]\n",
        "tfidf_scores = zip(feature_index, [lemmatized_unigram_tf_idf_vectors[0, x] for x in feature_index])\n",
        "for w, s in [(feature_names[i], s) for (i, s) in tfidf_scores]:\n",
        "    print(w, s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkDb0Wg0wFBW",
        "outputId": "2964964d-65d7-445e-d9c4-e50d0709b722"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "The shape of the tf-idf vectors (number of documents, number of features) for unigram model is\n",
            "(1143, 348)\n",
            "\n",
            "The tf-idf values of the first document (unigrams)\n",
            "\n",
            "wide 0.42968762964661683\n",
            "two 0.14912427121218227\n",
            "studi 0.14646986558212088\n",
            "set 0.5005073512666091\n",
            "purpos 0.23066025317240396\n",
            "neural 0.19965077426086789\n",
            "identifi 0.2085452725089655\n",
            "give 0.1956466039096827\n",
            "experi 0.1696179128512244\n",
            "estim 0.21224590314532887\n",
            "convolut 0.21896054598615544\n",
            "compar 0.14800420839493267\n",
            "collect 0.22261683102604074\n",
            "area 0.3912932078193654\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clustering the documents based on unigram tf-idf vectorizer\n",
        "\n",
        "min_score = 1e6\n",
        "best_k = 0\n",
        "for i in range(3,11):\n",
        "    kmeans = KMeans(n_clusters=i, n_init=20)\n",
        "    kmeans.fit(lemmatized_unigram_tf_idf_vectors)\n",
        "    labels = kmeans.labels_\n",
        "    db_index = davies_bouldin_score(lemmatized_unigram_tf_idf_vectors.toarray(), labels)\n",
        "    if db_index < min_score:\n",
        "        min_score = db_index\n",
        "        best_k = i\n",
        "\n",
        "print(\"Optimal number of clusters of the unigram model:\", best_k)\n",
        "print(\"Davies-Bouldin Index of the unigram model:\", min_score, \"\\n\")\n",
        "kmeans = KMeans(n_clusters=best_k, n_init=10)\n",
        "kmeans.fit(lemmatized_unigram_tf_idf_vectors)\n",
        "labels = kmeans.labels_\n",
        "db_index = davies_bouldin_score(lemmatized_unigram_tf_idf_vectors.toarray(), labels)\n",
        "\n",
        "clusters = {i: [] for i in range(best_k)}\n",
        "\n",
        "for point, label in zip(filtered_tokens_list, labels):\n",
        "    clusters[label].append(point)\n",
        "\n",
        "for i in range(best_k):\n",
        "    listofcluster = [ item for elem in clusters[i] for item in elem]\n",
        "    cluster_freq = FreqDist(listofcluster)\n",
        "    print(\"Cluster \", i, \":\", cluster_freq.most_common(15))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rer7G6pnwHcm",
        "outputId": "62978508-3c43-4d61-b7e8-4b2f3fe1f646"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal number of clusters of the unigram model: 5\n",
            "Davies-Bouldin Index of the unigram model: 4.709833356812028 \n",
            "\n",
            "Cluster  0 : [('vision', 319), ('object', 312), ('studi', 301), ('differ', 288), ('control', 268), ('improv', 261), ('train', 248), ('featur', 247), ('task', 246), ('research', 237), ('measur', 234), ('dataset', 231), ('evalu', 226), ('accuraci', 226), ('deep', 223)]\n",
            "Cluster  1 : [('quantum', 246), ('cryptographi', 52), ('key', 45), ('protocol', 40), ('attack', 37), ('oper', 35), ('post-quantum', 31), ('state', 31), ('commun', 31), ('gate', 29), ('scheme', 28), ('time', 27), ('circuit', 27), ('architectur', 26), ('also', 25)]\n",
            "Cluster  2 : [('encrypt', 302), ('scheme', 277), ('key', 198), ('cryptographi', 189), ('attack', 167), ('protocol', 143), ('authent', 124), ('iot', 122), ('provid', 109), ('cloud', 109), ('effici', 100), ('devic', 96), ('cryptograph', 94), ('techniqu', 86), ('new', 79)]\n",
            "Cluster  3 : [('program', 345), ('code', 212), ('languag', 212), ('optim', 194), ('graph', 146), ('memori', 145), ('transform', 134), ('parallel', 131), ('techniqu', 106), ('time', 102), ('show', 97), ('problem', 96), ('new', 92), ('analysi', 90), ('regist', 90)]\n",
            "Cluster  4 : [('relat', 305), ('queri', 261), ('sql', 82), ('manag', 78), ('store', 65), ('languag', 64), ('user', 63), ('schema', 56), ('graph', 55), ('differ', 53), ('effici', 53), ('ontolog', 53), ('structur', 53), ('analysi', 51), ('time', 49)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Therefore, the solution with lemmatization seems to have 5 topics (The order of the topics may randomly change each time the algorithm is run):\n",
        "\n",
        "- Topic 1: General programming and operating system/hardware\n",
        "- Topic 2: Quantum studies and application in security\n",
        "- Topic 3: Database, SQL and queries\n",
        "- Topic 4: Computer vision and robotics\n",
        "- Topic 5: Security and cryptography\n"
      ],
      "metadata": {
        "id": "-GbQJiXReEWt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Experiment with SVD (unigram tf-idf vectorizer)"
      ],
      "metadata": {
        "id": "lnRBSegMGPh6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVD (Singular Value Decomposition) is a dimensionality reduction technique used as LSA (Latent Semantic Analysis) in text clustering and topic modeling. SVC is applied after preprocessing but before clustering."
      ],
      "metadata": {
        "id": "27nc73kzenhp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'unigram_tf_idf_vectors' is your TF-IDF matrix from the TfidfVectorizer\n",
        "# Ignoring terms that appear in less than 5% of the documents or in more than 25% of the documents\n",
        "\n",
        "unigram_tfidf_vectorizer = TfidfVectorizer(\n",
        "    min_df=0.05,\n",
        "    max_df=0.25,\n",
        "    smooth_idf=False,\n",
        "    norm='l2',            # Ensures all our feature vectors have a euclidian norm of 1\n",
        "    ngram_range=(1,1)     # Extract only unigrams\n",
        ")\n",
        "\n",
        "#only tf part:\n",
        "#tfidf_vectorizer = TfidfVectorizer(use_idf=False)\n",
        "\n",
        "unigram_tfidf_vectorizer.fit(SVD_cleaned_documents)\n",
        "unigram_tf_idf_vectors = unigram_tfidf_vectorizer.transform(SVD_cleaned_documents)\n",
        "\n",
        "print(\"\\nThe shape of the tf-idf vectors (number of documents, number of features) for unigram model is\")\n",
        "print(unigram_tf_idf_vectors.shape)\n",
        "\n",
        "\n",
        "# Clustering the documents based on unigram tf-idf vectorizer\n",
        "\n",
        "min_score = 1e6\n",
        "best_k = 0\n",
        "for i in range(3,11):\n",
        "    kmeans = KMeans(n_clusters=i, n_init=20)\n",
        "    kmeans.fit(unigram_tf_idf_vectors)\n",
        "    labels = kmeans.labels_\n",
        "    db_index = davies_bouldin_score(unigram_tf_idf_vectors.toarray(), labels)\n",
        "    if db_index < min_score:\n",
        "        min_score = db_index\n",
        "        best_k = i\n",
        "\n",
        "print(\"Optimal number of clusters of the unigram model:\", best_k)\n",
        "print(\"Davies-Bouldin Index of the unigram model:\", min_score, \"\\n\")\n",
        "kmeans = KMeans(n_clusters=best_k, n_init=10)\n",
        "kmeans.fit(unigram_tf_idf_vectors)\n",
        "labels = kmeans.labels_\n",
        "db_index = davies_bouldin_score(unigram_tf_idf_vectors.toarray(), labels)\n",
        "\n",
        "clusters = {i: [] for i in range(best_k)}\n",
        "\n",
        "for point, label in zip(filtered_tokens_list, labels):\n",
        "    clusters[label].append(point)\n",
        "\n",
        "for i in range(best_k):\n",
        "    listofcluster = [ item for elem in clusters[i] for item in elem]\n",
        "    cluster_freq = FreqDist(listofcluster)\n",
        "    print(\"Cluster \", i, \":\", cluster_freq.most_common(15))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mB5sT8oiFro",
        "outputId": "4d4d7ed5-8961-432f-951a-a72a0c0635f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "The shape of the tf-idf vectors (number of documents, number of features) for unigram model is\n",
            "(1143, 349)\n",
            "Optimal number of clusters of the unigram model: 5\n",
            "Davies-Bouldin Index of the unigram model: 4.8797884670479 \n",
            "\n",
            "Cluster  0 : [('encrypt', 296), ('scheme', 274), ('key', 196), ('cryptographi', 183), ('attack', 167), ('protocol', 149), ('authent', 124), ('iot', 122), ('cloud', 109), ('provid', 107), ('effici', 99), ('cryptograph', 93), ('devic', 91), ('techniqu', 83), ('new', 79)]\n",
            "Cluster  1 : [('quantum', 252), ('cryptographi', 52), ('key', 45), ('protocol', 40), ('oper', 38), ('attack', 37), ('state', 33), ('gate', 32), ('circuit', 32), ('post-quantum', 31), ('program', 31), ('commun', 31), ('time', 31), ('also', 29), ('scheme', 28)]\n",
            "Cluster  2 : [('control', 258), ('studi', 221), ('measur', 209), ('differ', 175), ('estim', 163), ('test', 163), ('structur', 156), ('task', 154), ('provid', 152), ('improv', 149), ('environ', 142), ('evalu', 141), ('work', 141), ('vision', 135), ('sensor', 132)]\n",
            "Cluster  3 : [('object', 272), ('deep', 200), ('dataset', 198), ('featur', 193), ('train', 187), ('vision', 184), ('video', 163), ('neural', 149), ('visual', 148), ('accuraci', 134), ('track', 133), ('differ', 126), ('research', 126), ('improv', 120), ('recognit', 112)]\n",
            "Cluster  4 : [('program', 332), ('relat', 306), ('languag', 275), ('queri', 257), ('code', 217), ('optim', 201), ('graph', 200), ('memori', 141), ('transform', 138), ('time', 136), ('parallel', 136), ('techniqu', 134), ('show', 129), ('effici', 125), ('analysi', 125)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.sparse import vstack\n",
        "\n",
        "# Divide the TF-IDF matrix into separate matrices for each cluster\n",
        "clustered_documents = {i: [] for i in range(best_k)}\n",
        "for doc_id, cluster_id in enumerate(labels):\n",
        "    clustered_documents[cluster_id].append(unigram_tf_idf_vectors[doc_id])\n",
        "\n",
        "# Apply SVD to each cluster's TF-IDF matrix and interpret the leading singular vector\n",
        "for i in range(best_k):\n",
        "    # Convert the list of TF-IDF vectors for this cluster to a sparse matrix\n",
        "    cluster_tf_idf_matrix = vstack(clustered_documents[i])\n",
        "\n",
        "    svd = TruncatedSVD(n_components=1)\n",
        "    svd.fit(cluster_tf_idf_matrix)\n",
        "    leading_singular_vector = svd.components_[0]\n",
        "\n",
        "    terms = unigram_tfidf_vectorizer.get_feature_names_out()\n",
        "\n",
        "    # Get the terms with the highest coefficients in the leading singular vector\n",
        "    top_indices = leading_singular_vector.argsort()[-5:][::-1]\n",
        "    top_terms = [(terms[idx], leading_singular_vector[idx]) for idx in top_indices]\n",
        "\n",
        "    print(f\"\\nCluster {i} leading singular vector terms:\")\n",
        "    for term, coefficient in top_terms:\n",
        "        print(f\"{term} (coefficient: {coefficient:.4f})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkiHncTspq3X",
        "outputId": "776262d6-919c-44b5-9b0b-704199f7ebda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Cluster 0 leading singular vector terms:\n",
            "encrypt (coefficient: 0.4741)\n",
            "scheme (coefficient: 0.3690)\n",
            "key (coefficient: 0.2680)\n",
            "attack (coefficient: 0.2421)\n",
            "cryptographi (coefficient: 0.2371)\n",
            "\n",
            "Cluster 1 leading singular vector terms:\n",
            "program (coefficient: 0.4419)\n",
            "languag (coefficient: 0.3099)\n",
            "code (coefficient: 0.2745)\n",
            "graph (coefficient: 0.2196)\n",
            "memori (coefficient: 0.1874)\n",
            "\n",
            "Cluster 2 leading singular vector terms:\n",
            "queri (coefficient: 0.5814)\n",
            "relat (coefficient: 0.5026)\n",
            "manag (coefficient: 0.1621)\n",
            "store (coefficient: 0.1517)\n",
            "graph (coefficient: 0.1319)\n",
            "\n",
            "Cluster 3 leading singular vector terms:\n",
            "quantum (coefficient: 0.9091)\n",
            "protocol (coefficient: 0.1301)\n",
            "cryptographi (coefficient: 0.1226)\n",
            "key (coefficient: 0.1210)\n",
            "attack (coefficient: 0.0895)\n",
            "\n",
            "Cluster 4 leading singular vector terms:\n",
            "vision (coefficient: 0.1947)\n",
            "object (coefficient: 0.1771)\n",
            "deep (coefficient: 0.1485)\n",
            "track (coefficient: 0.1365)\n",
            "train (coefficient: 0.1352)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion of the topics of the documents"
      ],
      "metadata": {
        "id": "rCOVIADsH0UC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on all experiments and also the baseline, we can conclude that this corpus must have at least 5 topics. These are the topics that kept reoccuring in both the baseline and the experiments:\n",
        "\n",
        "- Topic 1: General programming and operating system/hardware, whose top keywords are program, language, code, graph, memory\n",
        "\n",
        "- Topic 2: Quantum studies and application in security, whose top keywords are quantum, protocol, cryptography, key and attack\n",
        "\n",
        "- Topic 3: Database, SQL and queries, whose top keywords are query, relational, management, store, graph\n",
        "\n",
        "- Topic 4: Computer vision and robotics, whose top keywords are vision, object, deep (possibly deep learning), track (possibly in reinforcement learning automation), train\n",
        "\n",
        "- Topic 5: Security and cryptography, whose top keywords are encryption, scheme, key, attack, cryptograph"
      ],
      "metadata": {
        "id": "-gUcIFFehxqm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4. Appendix**"
      ],
      "metadata": {
        "id": "XxjWbmP9__e3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "All the code for this exercise has been added with respect to each part for closest referencing. Therefore, we do not attach any more code here in the Appendix section"
      ],
      "metadata": {
        "id": "UedFuu1BBLnG"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}