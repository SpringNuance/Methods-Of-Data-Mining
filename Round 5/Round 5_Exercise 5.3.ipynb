{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Preprocessing NLP data\n",
    "\n",
    "Learning goal: preprocessing text data, detecting errors and special cases; how to increase frequency of important terms and collocations despite different spelling and grammatic forms\n",
    "\n",
    "In this task, we will practise preprocessing of text data with Python Natural Language Toolkit (nltk). The idea is that you can utilize the results in the homework task, even if you were using another programming language\n",
    "for the actual processing.\n",
    "\n",
    "Install packages nltk, scikit-learn and numpy with command pip3 install\n",
    "scikit-learn nltk numpy. There is also a book “Natural Language Processing with Python” https://www.nltk.org/book/ with examples.\n",
    "\n",
    "Load example data acmdocuments.txt from MyCourses. Each line is\n",
    "considered as one document. They are sentences from scientific abstracts in the ACM digital library https://dl.acm.org/. In MyCourses, you can find a code skeleton preprocSbS.py that you can use as a starting point, unless\n",
    "you already know how to do all preprocessing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) The main tasks of preprocessing text data are tokenization, lowercasing, removing punctuation, stemming (or lemmatization), and stop-word removal. However, order of these steps depends on the library and your implementation. The stopword list may contain only stopwords in their normal (unreduced) form, in a stemmed form, or with punctuation characters like (apostrophes). Lemmatization tools often require full sentences so that they can utilize part-of-speech analysis. The first task is always to determine the right order to do the preprocessing steps. Make a fast sanity check to the example code: is it performing the steps as desired? What would happen if you skipped lowercasing or performed stemming before stopword removal?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Check stopword removal and search examples of two types of errors: \n",
    "\n",
    "- (i) Stopwords (or other common and useless words in this context) that remain in the text, and \n",
    "\n",
    "- (ii) important words that are removed as stopwords (Hint: look important computer science abbreviations and notations in\n",
    "the NLTK stopword list). Estimate how serious these errors are (assuming we had a larger corpus of similar documents). How could you fix the (most serious) errors?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Check the quality of stemming (with Porter stemmer). Can you find errors where either \n",
    "\n",
    "- (i) two words having the same basic forms are reduced to different stems or \n",
    "- (ii) two words with different roots are reduced to the same stem? Test if the Snowball stemmer would do a better job! Are there errors where lemmatization could help?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) Check punctuation removal. Can you find errors where either \n",
    "- (i) punctuation that should be removed has remained or \n",
    "- (ii) punctuation that"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(e) Evaluate collocations/compound words (phrases of multiple consecutive words). Can you find examples of important collocations that occur in different forms: \n",
    "\n",
    "- (i) closed (constituent words catenated together), \n",
    "- (ii) hyphenated (hyphen between words), \n",
    "- (iii) open (space between words).\n",
    "\n",
    "Suggest a solution how to handle them!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
